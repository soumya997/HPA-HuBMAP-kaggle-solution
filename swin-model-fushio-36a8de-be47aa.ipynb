{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-16T12:00:09.07925Z","iopub.status.busy":"2022-09-16T12:00:09.07827Z","iopub.status.idle":"2022-09-16T12:00:09.085911Z","shell.execute_reply":"2022-09-16T12:00:09.08434Z","shell.execute_reply.started":"2022-09-16T12:00:09.079203Z"},"trusted":true},"outputs":[],"source":["# !pip install /kaggle/input/staintools-offline/spams-2.6.5.4-cp37-cp37m-linux_x86_64.whl\n","# !pip install /kaggle/input/staintools-offline/staintools-2.1.2-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-16T12:00:09.08969Z","iopub.status.busy":"2022-09-16T12:00:09.088823Z","iopub.status.idle":"2022-09-16T12:00:09.105214Z","shell.execute_reply":"2022-09-16T12:00:09.103883Z","shell.execute_reply.started":"2022-09-16T12:00:09.089645Z"},"trusted":true},"outputs":[],"source":["# import staintools\n","\n","# def get_target(organ_type):\n","#     if organ_type == \"kidney\":\n","#         target = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/15005.tiff\")\n","#         return target\n","#     elif organ_type == \"largeintestine\":\n","#         target = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/9777.tiff\")\n","#         return target\n","#     elif organ_type == \"lung\":\n","#         target = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/4301.tiff\")\n","#         return target\n","#     elif organ_type == \"prostate\":\n","#         target = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/12244.tiff\")\n","#         return target\n","#     elif organ_type == \"spleen\":\n","#         target = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/1123.tiff\")\n","#         return target"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-16T12:00:09.108459Z","iopub.status.busy":"2022-09-16T12:00:09.107806Z","iopub.status.idle":"2022-09-16T12:00:09.119012Z","shell.execute_reply":"2022-09-16T12:00:09.11748Z","shell.execute_reply.started":"2022-09-16T12:00:09.108417Z"},"trusted":true},"outputs":[],"source":["# import staintools\n","# target_kidney = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/15005.tiff\")\n","# target_largeintestine = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/9777.tiff\")\n","# target_lung = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/4301.tiff\")\n","# target_prostate = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/12244.tiff\")\n","# target_spleen = staintools.read_image(\"/kaggle/input/hubmap-organ-segmentation/train_images/1123.tiff\")\n","# print('速度')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-16T12:00:09.33431Z","iopub.status.busy":"2022-09-16T12:00:09.332473Z","iopub.status.idle":"2022-09-16T12:00:40.961845Z","shell.execute_reply":"2022-09-16T12:00:40.960395Z","shell.execute_reply.started":"2022-09-16T12:00:09.334261Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm\n","import gc\n","import tifffile as tiff\n","import tifffile\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from rasterio.windows import Window\n","import pandas as pd\n","import rasterio\n","\n","is_amp = True\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","import sys\n","\n","sys.path.append(\"../input/deeplearnings\")\n","from dataset import *\n","sys.path.append(\"../input/deeplearnings\")\n","from imagecut import *\n","from imageplt import *\n","from model import *\n","from model_coat_daformer import *\n","from model_pvt_v2_daformer import *\n","from model_coat_daformer_2 import *\n","from My_model_daformer_coat import *\n","def rle2mask(mask_rle, shape=(1600, 256)):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (width,height) of array to return\n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape).T\n","\n","\n","tensor_list = [\n","    'mask', 'image', 'organ',\n","]\n","\n","\n","def null_collate(batch):\n","    d = {}\n","    key = batch[0].keys()\n","    for k in key:\n","        v = [b[k] for b in batch]\n","        if k in tensor_list:\n","            v = torch.stack(v)\n","        d[k] = v\n","    # d['mask'] = d['mask'].unsqueeze(1)\n","    # d['organ'] = d['organ'].reshape(-1)\n","    return d\n","\n","\n","def image_to_tensor(image, mode='bgr'):  # image mode\n","    if mode == 'bgr':\n","        image = image[:, :, ::-1]\n","    x = image\n","    x = x.transpose(2, 0, 1)\n","    x = np.ascontiguousarray(x)\n","    x = torch.tensor(x, dtype=torch.float)\n","    return x\n","\n","\n","def mask_to_tensor(mask):\n","    x = mask\n","    x = torch.tensor(x, dtype=torch.float)\n","    return x\n","\n","\n","def tensor_to_mask(x):\n","    mask = x.data.cpu().numpy()\n","    mask = mask.astype(np.float32)\n","    return mask\n","imaging_measurements = {\n","    'hpa': {\n","        'pixel_size': {\n","            'kidney': 0.4,\n","            'prostate': 0.4,\n","            'largeintestine': 0.4,\n","            'spleen': 0.4,\n","            'lung': 0.4\n","        },\n","        'tissue_thickness': {\n","            'kidney': 4,\n","            'prostate': 4,\n","            'largeintestine': 4,\n","            'spleen': 4,\n","            'lung': 4\n","        }\n","    },\n","    'hubmap': {\n","        'pixel_size': {\n","            'kidney': 0.5,\n","            'prostate': 6.263,\n","            'largeintestine': 0.229,\n","            'spleen': 0.4945,\n","            'lung': 0.7562\n","        },\n","        'tissue_thickness': {\n","        'kidney': 10,\n","            'prostate': 5,\n","            'largeintestine': 8,\n","            'spleen': 4,\n","            'lung': 5\n","        }\n","    }\n","}\n","\n","\n","def pixel_size(image, domain_pixel_size, target_pixel_size):\n","    pixel_size_scale_factor = domain_pixel_size / target_pixel_size\n","\n","    image_resized = cv2.resize(\n","        image,\n","        dsize=None,\n","        fx=pixel_size_scale_factor,\n","        fy=pixel_size_scale_factor,\n","        interpolation=cv2.INTER_CUBIC\n","    )\n","\n","    image_resizedd = cv2.resize(\n","        image_resized,\n","        dsize=(\n","            image.shape[1],\n","            image.shape[0]\n","        ),\n","        interpolation=cv2.INTER_CUBIC\n","    )\n","    return image_resizedd\n","\n","\n","##数据处理\n","class HubmapDataset(Dataset):\n","    def __init__(self, df, augment=None,image_size=1024):\n","        data_path = \"../input/hubmap-organ-segmentation\"\n","        df['image_path'] = df['id'].apply(lambda x: os.path.join(data_path, 'test_images', str(x) + '.tiff'))\n","        self.df = df\n","        self.augment = augment\n","        self.length = len(self.df)\n","        self.image_size=image_size\n","\n","    def __str__(self):\n","        string = ''\n","        string += '\\tlen = %d\\n' % len(self)\n","\n","        d = self.df.organ.value_counts().to_dict()\n","        for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n","            string += '%24s %3d (%0.3f) \\n' % (k, d.get(k, 0), d.get(k, 0) / len(self.df))\n","        return string\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, index):\n","        img_path = self.df.loc[index, 'image_path']\n","        image = tifffile.imread(img_path) \n","        \n","#         domain_pixel_size = imaging_measurements['hpa']['pixel_size'][row['organ']]\n","#         target_pixel_size = imaging_measurements['hubmap']['pixel_size'][row['organ']]\n","#         image = pixel_size(image, domain_pixel_size, target_pixel_size)\n","        \n","\n","#         target = get_target(self.df.organ.values[0])##添加-jion\n","#         image = staintools.LuminosityStandardizer.standardize(image)\n","        \n","#         # Stain normalize\n","#         normalizer = staintools.StainNormalizer(method='vahadane')\n","#         normalizer.fit(target)\n","#         transformed3 = normalizer.transform(image)\n","#         image = transformed3\n","        \n","        \n","\n","        image = image.astype(np.float32) / 255\n","\n","        #image_size = 1024\n","        if self.image_size>1024:\n","            image = cv2.resize(image, dsize=(1024, 1024), interpolation=cv2.INTER_LINEAR)\n","        else:\n","            image = cv2.resize(image, dsize=(self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)\n","        \n","        r = {}\n","        r['index'] = index\n","        r['id'] = self.df['id'][0]\n","        r['image'] = image_to_tensor(image)\n","        return r\n","\n","\n","############################################################\n","####### Validation\n","############################################################\n","def validate(net, valid_loader):\n","    net = net.eval()\n","    image_size = int(valid_loader.dataset.df['img_height'][0])\n","    for t, batch in enumerate(valid_loader):\n","        net.output_type = ['inference']\n","        with torch.no_grad():\n","            with amp.autocast(enabled=is_amp):\n","                batch['image'] = batch['image'].to(device)\n","                output = net(batch)\n","        probability = output['probability']\n","        p = tensor_to_mask(probability[0, 0])\n","        mask_Predict = cv2.resize(p, dsize=(image_size, image_size), interpolation=cv2.INTER_LINEAR)\n","\n","    return mask_Predict\n","\n","\n","def get_learning_rate(optimizer):\n","    return optimizer.param_groups[0]['lr']\n","\n","\n","##数据处理\n","def img2tensor(img, dtype: np.dtype = np.float32):\n","    if img.ndim == 2: img = np.expand_dims(img, 2)\n","    img = np.transpose(img, (2, 0, 1))\n","    return torch.from_numpy(img.astype(dtype, copy=False))\n","\n","\n","def rle_encode_less_memory(img):\n","    # the image should be transposed\n","    pixels = img.T.flatten()\n","    # This simplified method requires first and last pixel to be zero\n","    pixels[0] = 0\n","    pixels[-1] = 0\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n","    runs[1::2] -= runs[::2]\n","\n","    return ' '.join(str(x) for x in runs)\n","\n","\n","def valid_augment5(image, mask, organ=None):\n","    return image, mask\n","def Patch_validate(net, valid_loader):\n","    net = net.eval()\n","    image_size = int(valid_loader.dataset.df['img_height'][0])\n","    for t, batch in enumerate(valid_loader):\n","        net.output_type = ['inference']\n","        with torch.no_grad():\n","            with amp.autocast(enabled=is_amp):\n","                # batch['image'] = batch['image'].to(device)\n","                batch_list = batch['image'].detach().numpy()\n","                batch_list = np.squeeze(batch_list)\n","                batch_Image_ = batch_list.transpose(1, 2, 0)\n","\n","                image_plt = batch_Image_\n","                image_plt = image_plt[:, :, ::-1]\n","                batch_list = do_image_cut(batch_Image_, 512)\n","\n","                for index, image in enumerate(batch_list):\n","                    image = image[:, :, ::-1]\n","                    batch_list[index] = image.transpose(2, 0, 1)\n","                    batch_list[index] = np.ascontiguousarray(batch_list[index])\n","                batch['image'] = torch.tensor(batch_list, dtype=torch.float)\n","                batch['image'] = batch['image'].to(device)\n","                output = net(batch)\n","\n","        probability = output['probability']\n","\n","        # p = tensor_to_mask(probability[0, 0])\n","        p = probability.data.cpu().numpy()\n","        p = np.squeeze(p)\n","        mask_Predict = mask_merge(p, (image_plt.shape[0], image_plt.shape[1]), 512)\n","\n","\n","    return mask_Predict,batch_Image_\n","def Patch_valid_ImageShows(Data_Pd, model, imagesizes):\n","    ##读取数据\n","    valid_dataset = HubmapDataset(Data_Pd, valid_augment5, imagesizes)\n","    valid_dataset.fnames = Data_Pd['id'][0]\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        sampler=SequentialSampler(valid_dataset),\n","        batch_size=1,\n","        drop_last=False,\n","        num_workers=0,\n","        pin_memory=False,\n","        collate_fn=null_collate,\n","    )\n","    preds,Image_ = Patch_validate(model, valid_loader)\n","    del valid_dataset, valid_loader\n","\n","    return preds,Image_\n","\n","\n","def valid_ImageShows(Data_Pd,model,imagesizes):\n","\n","    ##读取数据\n","    valid_dataset = HubmapDataset(Data_Pd, valid_augment5,imagesizes)\n","    valid_dataset.fnames = Data_Pd['id'][0]\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        sampler=SequentialSampler(valid_dataset),\n","        batch_size=1,\n","        drop_last=False,\n","        num_workers=0,\n","        pin_memory=False,\n","        collate_fn=null_collate,\n","    )\n","    preds = validate(model, valid_loader)\n","    del valid_dataset, valid_loader\n","\n","    return preds\n","def ListModel_state(model_LD,state_dict_LD):\n","    model_LD.load_state_dict(state_dict_LD)\n","    model_LD.float()\n","    model_LD.eval()\n","    model_LD.to(device)\n","\n","    return model_LD\n","if __name__ == '__main__':\n","\n","    #TH = 0.3 # threshold for positive predictions\n","    identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n","    DATA = '../input/hubmap-organ-segmentation/test_images/'\n","    df_sample = pd.read_csv('../input/hubmap-organ-segmentation/test.csv')\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n"," #Coat2_Fold0_10080  Coat2_Fold1_12390 Coat2_Fold2_19320\n","    Coat_Tensorform = ['../input/deeplearnings/Coat_Fold2_20370.model.pth',\n","                      '../input/deeplearnings/Coat2_Fold2_19320.model.pth']\n","    Frist_Coat_Tensorform=['../input/deeplearnings/Frist_Coat_Fold0_34860.model.pth']\n","    Y_Coat_Tensorform = ['../input/deeplearnings/Y_Coat_00010600_512X512.model.pth']\n","    \n","    #Coat2_Fold2_19320  Fold3_169830  PTV2_Fold0_20790  Coat2_Fold0_10080  Coat2_Fold1_12390 Coat2_Fold2_19320\n","    MY_Swin_Transform_Tensorform=['../input/deeplearnings/Fold3_169830_762and0.114.pth',\n","                                 '../input/deeplearnings/Swin_Fold1_15198.model.pth']\n","    #Coat_Tensorform=[]\n","    #PVT2_Model_Tensorform=['../input/deeplearnings/PVT2_Fold3_20790.model.pth']\n","    Swin_Transform_Tensorform=['../input/deeplearnings/Y_Swin_Transform_Fold_2_6912.model.pth',\n","                              '../input/deeplearnings/Y_Swin_Transform_Fold_3_6237.model.pth',\n","                              '../input/deeplearnings/Y_Swin_Transform_Fold_1_6912.model.pth']\n","    PVT2_Model_Tensorform=['../input/deeplearnings/PVT2/PTV2_Fold0_20790.model.pth',#IB=0.74\n","                           '../input/deeplearnings/PVT2_Fold-1_26880.model.pth',\n","                           '../input/deeplearnings/PVT2_Fold3_20790.model.pth',\n","                          '../input/deeplearnings/PVT2/PTV2_Fold2_18270.model.pth']\n","#Coat2_Fold1_12390 Coat2_Fold2_19320  Fold3_169830 PTV2_Fold0_20790 PVT2_Fold-1_26880  PVT2_Fold2_19110  Coat2_Fold0_10080  Coat2_Fold1_12390 Coat2_Fold2_19320\n","    \n","    Patch_Coat_Tensorform = ['../input/deeplearnings/Caot_Fold4_spleen00011610.model.pth',\n","                             '../input/deeplearnings/Caot_Fold4_largeintestine00009024.model.pth',\n","                             '../input/deeplearnings/Caot_Fold4_prostate00008550.model.pth',\n","                             '../input/deeplearnings/Caot_Fold4_kidney00009600.model.pth',\n","                            '../input/deeplearnings/Coat_Fold2_20370.model.pth']#'Coat_spleen00033024.model.pth\n","    organ_Dict = {'spleen': 0, 'largeintestine': 1, 'prostate': 2,'kidney': 3,'lung': 4 }\n","    organs_lists = ['kidney', 'largeintestine', 'lung', 'prostate', 'spleen']\n","    names, preds = [], []\n","    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n","        Data_Type=str(row['data_source'])\n","        idx = str(row['id'])\n","        organ_=str(row['organ'])\n","        data = rasterio.open(os.path.join(DATA, idx + '.tiff'),\n","                             transform=identity, num_threads='all_cpus')\n","        ##生成需要文件\n","        colname_ = ['id','organ', 'img_height', 'img_width']\n","        values = [idx,organ_,\n","                  data.meta['width'],\n","                  data.meta['height']]\n","        My_Submitfile = pd.DataFrame(np.array(values), index=np.array(colname_)).T\n","        mask = np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","        \n","        \n","        ###Patch_Coat_Model\n","        #Patch_Coat_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","        if organ_Dict[organ_]<=3:\n","            \n","            if Data_Type=='HPA':\n","                TH=0.3\n","            else:\n","                TH=0.3\n","            \n","            \n","            \n","            state_dict_Coat = torch.load(Patch_Coat_Tensorform[organ_Dict[organ_]], map_location=None)['state_dict']\n","            Patch_model_Coat = Coat_Net_0920()\n","            Patch_model_Coat = ListModel_state(Patch_model_Coat, state_dict_Coat)\n","            Patch_List_Image_Coat, Image_ = Patch_valid_ImageShows(Data_Pd=My_Submitfile, model=Patch_model_Coat,imagesizes=2022)\n","            if (data.meta['width'] != Patch_List_Image_Coat.shape[0]):\n","                Patch_List_Image_Coat = cv2.resize(Patch_List_Image_Coat, dsize=(data.meta['width'], data.meta['height']),\n","                                               interpolation=cv2.INTER_LINEAR)\n","            Patch_Coat_mask=Patch_List_Image_Coat\n","            \n","            Frist_Coat_mask = np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for Coat_Transform_model in Frist_Coat_Tensorform:\n","                state_dict_Coat = torch.load(Coat_Transform_model, map_location=None)['state_dict']\n","                model_Coat = Net_Coat()\n","                model_Coat=ListModel_state(model_Coat,state_dict_Coat)\n","                List_Image_Coat=valid_ImageShows(Data_Pd=My_Submitfile, model=model_Coat,imagesizes=1024)\n","                Frist_Coat_mask+=List_Image_Coat\n","            Frist_Coat_mask=Frist_Coat_mask/len(Frist_Coat_Tensorform)\n","            \n","            \n","            \n","            PVT2_mask = np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for pvt_model in PVT2_Model_Tensorform:\n","                state_dict_PVT2 = torch.load(pvt_model, map_location=None)['state_dict']\n","                model_PVT2 = Net_PVT2()\n","                model_PVT2 =ListModel_state(model_PVT2,state_dict_PVT2)\n","                List_Image_PVT2 = valid_ImageShows(Data_Pd=My_Submitfile, model=model_PVT2,imagesizes=768)\n","                PVT2_mask+=List_Image_PVT2\n","            PVT2_mask=PVT2_mask/len(PVT2_Model_Tensorform)\n","            \n","            \n","            My_Swin_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for Swin_Transform_model in MY_Swin_Transform_Tensorform:\n","                state_dict_Swin_Transform = torch.load(Swin_Transform_model, map_location=None)['state_dict']\n","                model_Swin_Transform = Net_Swin_Transform()\n","                model_Swin_Transform =ListModel_state(model_Swin_Transform,state_dict_Swin_Transform)\n","                List_Image_Swin_Transform = valid_ImageShows(Data_Pd=My_Submitfile, model=model_Swin_Transform,imagesizes=768)\n","                My_Swin_mask+=List_Image_Swin_Transform\n","            My_Swin_mask=My_Swin_mask/len(MY_Swin_Transform_Tensorform)\n","#             PVT2_mask=(PVT2_mask+My_Swin_mask)/2\n","            \n","            \n","            Swin_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for Swin_Transform_model in Swin_Transform_Tensorform:\n","                state_dict_Swin_Transform = torch.load(Swin_Transform_model, map_location=None)['state_dict']\n","                model_Swin_Transform = Net_Swin_Transform()\n","                model_Swin_Transform =ListModel_state(model_Swin_Transform,state_dict_Swin_Transform)\n","                List_Image_Swin_Transform = valid_ImageShows(Data_Pd=My_Submitfile, model=model_Swin_Transform,imagesizes=768)\n","                Swin_mask+=List_Image_Swin_Transform\n","            Swin_mask=Swin_mask/len(Swin_Transform_Tensorform)\n","            \n","            Coat_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            ###Coat_Model\n","            for Coat_Transform_model in Coat_Tensorform:\n","                state_dict_Coat = torch.load(Coat_Transform_model, map_location=None)['state_dict']\n","                model_Coat = Coat_Net2()\n","                model_Coat=ListModel_state(model_Coat,state_dict_Coat)\n","                List_Image_Coat=valid_ImageShows(Data_Pd=My_Submitfile, model=model_Coat,imagesizes=1024)\n","                Coat_mask+=List_Image_Coat\n","            Coat_mask=Coat_mask/len(Coat_Tensorform)\n","            \n","            Patch_Coat_mask=(PVT2_mask+Patch_Coat_mask+Swin_mask+Coat_mask+My_Swin_mask+Frist_Coat_mask)/6\n","\n","            #TH=0.3\n","            mask=Patch_Coat_mask\n","            mask[mask > TH] = 1\n","            mask[mask < 1] = 0\n","            preds.append(rle_encode_less_memory(mask))\n","            names.append(int(idx))\n","            \n","        else:\n","\n","            \n","            Coat_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            ###Coat_Model\n","            for Coat_Transform_model in Coat_Tensorform:\n","                state_dict_Coat = torch.load(Coat_Transform_model, map_location=None)['state_dict']\n","                model_Coat = Coat_Net2()\n","                model_Coat=ListModel_state(model_Coat,state_dict_Coat)\n","                List_Image_Coat=valid_ImageShows(Data_Pd=My_Submitfile, model=model_Coat,imagesizes=1024)\n","                Coat_mask+=List_Image_Coat\n","            Coat_mask=Coat_mask/len(Coat_Tensorform)\n","            My_Swin_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for Swin_Transform_model in MY_Swin_Transform_Tensorform:\n","                state_dict_Swin_Transform = torch.load(Swin_Transform_model, map_location=None)['state_dict']\n","                model_Swin_Transform = Net_Swin_Transform()\n","                model_Swin_Transform =ListModel_state(model_Swin_Transform,state_dict_Swin_Transform)\n","                List_Image_Swin_Transform = valid_ImageShows(Data_Pd=My_Submitfile, model=model_Swin_Transform,imagesizes=768)\n","                My_Swin_mask+=List_Image_Swin_Transform\n","            My_Swin_mask=My_Swin_mask/len(MY_Swin_Transform_Tensorform)\n","            Frist_Coat_mask = np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for Coat_Transform_model in Frist_Coat_Tensorform:\n","                state_dict_Coat = torch.load(Coat_Transform_model, map_location=None)['state_dict']\n","                model_Coat = Net_Coat()\n","                model_Coat=ListModel_state(model_Coat,state_dict_Coat)\n","                List_Image_Coat=valid_ImageShows(Data_Pd=My_Submitfile, model=model_Coat,imagesizes=1024)\n","                Frist_Coat_mask+=List_Image_Coat\n","            Frist_Coat_mask=Frist_Coat_mask/len(Frist_Coat_Tensorform)\n","            \n","            PVT2_mask = np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for pvt_model in PVT2_Model_Tensorform:\n","                state_dict_PVT2 = torch.load(pvt_model, map_location=None)['state_dict']\n","                model_PVT2 = Net_PVT2()\n","                model_PVT2 =ListModel_state(model_PVT2,state_dict_PVT2)\n","                List_Image_PVT2 = valid_ImageShows(Data_Pd=My_Submitfile, model=model_PVT2,imagesizes=768)\n","                PVT2_mask+=List_Image_PVT2\n","            PVT2_mask=PVT2_mask/len(PVT2_Model_Tensorform)\n","            \n","            Swin_mask=np.zeros((data.meta['width'], data.meta['width']), dtype=np.float32)\n","            for Swin_Transform_model in Swin_Transform_Tensorform:\n","                state_dict_Swin_Transform = torch.load(Swin_Transform_model, map_location=None)['state_dict']\n","                model_Swin_Transform = Net_Swin_Transform()\n","                model_Swin_Transform =ListModel_state(model_Swin_Transform,state_dict_Swin_Transform)\n","                List_Image_Swin_Transform = valid_ImageShows(Data_Pd=My_Submitfile, model=model_Swin_Transform,imagesizes=768)\n","                Swin_mask+=List_Image_Swin_Transform\n","            Swin_mask=Swin_mask/len(Swin_Transform_Tensorform)\n","            Patch_Coat_mask=(Swin_mask+PVT2_mask+Coat_mask+My_Swin_mask+Frist_Coat_mask)/5\n","            TH=0.1\n","            mask=Patch_Coat_mask\n","            mask[mask > TH] = 1\n","            mask[mask < 1] = 0\n","            preds.append(rle_encode_less_memory(mask))\n","            names.append(int(idx))\n","       \n","\n","\n","        del data, My_Submitfile, mask,Patch_Coat_mask#,Coat_mask,Swin_mask,PVT2_mask\n","        gc.collect()\n","    df = pd.DataFrame({'id': names, 'rle': preds})\n","    df.to_csv('submission.csv', index=False)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.0 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"vscode":{"interpreter":{"hash":"21a2a557654fc1676068684031cf9bb9dfda94e124d3623f4e9c9ed764d794ac"}}},"nbformat":4,"nbformat_minor":4}

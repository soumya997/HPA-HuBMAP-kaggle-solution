{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007246,"end_time":"2022-08-16T19:02:52.302567","exception":false,"start_time":"2022-08-16T19:02:52.295321","status":"completed"},"tags":[]},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Sep 22 21:33:33 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n","| 28%   40C    P0    36W / 250W |    412MiB / 11016MiB |     24%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      2755      G   /usr/lib/xorg/Xorg                 18MiB |\n","|    0   N/A  N/A      2896      G   /usr/bin/gnome-shell               71MiB |\n","|    0   N/A  N/A      3354      G   /usr/lib/xorg/Xorg                122MiB |\n","|    0   N/A  N/A      3542      G   /usr/bin/gnome-shell               25MiB |\n","|    0   N/A  N/A      4337      G   ...419168791412886806,131072       54MiB |\n","|    0   N/A  N/A      6284      G   ...RendererForSitePerProcess      114MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-17T06:18:41.221301Z","iopub.status.busy":"2022-08-17T06:18:41.220595Z","iopub.status.idle":"2022-08-17T06:18:45.749538Z","shell.execute_reply":"2022-08-17T06:18:45.748207Z","shell.execute_reply.started":"2022-08-17T06:18:41.221215Z"},"papermill":{"duration":5.945852,"end_time":"2022-08-16T19:02:58.254572","exception":false,"start_time":"2022-08-16T19:02:52.308720","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/lakshita/somusan/hubmap_kaggle/.venv/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import time\n","import random\n","\n","import torch\n","from torch import nn\n","import torch.cuda.amp as amp\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import RandomSampler \n","from torch.utils.data import SequentialSampler\n","import torch.nn.functional as F\n","# from torchmetrics.functional import dice_score\n","from torch.optim.lr_scheduler import StepLR\n","import tifffile\n","from fastai.vision.all import *\n","\n","from collections import defaultdict\n","\n","import torch\n","from torch.optim.optimizer import Optimizer\n","import itertools as it\n","\n","is_amp = True\n","import logging\n","\n","from sklearn.model_selection import KFold\n","\n","\n","from itertools import repeat\n","import collections.abc\n","import math\n","import torch\n","from torch import Tensor\n","from torch.optim.optimizer import Optimizer, required\n","from collections import defaultdict\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import sys\n","sys.path.append('/home/lakshita/somusan/hubmap_kaggle/nbs/timm-pytorch-image-models/pytorch-image-models-master')\n","import timm\n","\n","sys.path.append('/home/lakshita/somusan/hubmap_kaggle/nbs/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')\n","\n","from efficientnet_pytorch import EfficientNet\n","from efficientnet_pytorch.utils import url_map, url_map_advprop, get_model_params"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005742,"end_time":"2022-08-16T19:02:58.266495","exception":false,"start_time":"2022-08-16T19:02:58.260753","status":"completed"},"tags":[]},"source":["## Directory"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:45.760015Z","iopub.status.busy":"2022-08-17T06:18:45.758472Z","iopub.status.idle":"2022-08-17T06:18:48.126151Z","shell.execute_reply":"2022-08-17T06:18:48.124647Z","shell.execute_reply.started":"2022-08-17T06:18:45.759971Z"},"papermill":{"duration":2.014493,"end_time":"2022-08-16T19:03:00.286680","exception":false,"start_time":"2022-08-16T19:02:58.272187","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/home/lakshita/somusan/hubmap_kaggle/nbs/result’: File exists\n","mkdir: cannot create directory ‘/home/lakshita/somusan/hubmap_kaggle/nbs/checkpoint’: File exists\n"]}],"source":["!mkdir /home/lakshita/somusan/hubmap_kaggle/nbs/result\n","!mkdir /home/lakshita/somusan/hubmap_kaggle/nbs/checkpoint\n","\n","# root_dir = '/home/lakshita/somusan/hubmap_kaggle/nbs'\n","# #pretrain_dir = '/kaggle/input/swin-tiny-small-22k-pretrained/'\n","\n","# TRAIN = '/home/lakshita/somusan/hubmap_kaggle/nbs/aug_lung_data/hubmap-22-aug-pixel-size'\n","# LABELS = '/home/lakshita/somusan/hubmap_kaggle/nbs/aug_lung_data/only_lung.csv' #only lungs\n","\n","root_dir = '/home/lakshita/somusan/hubmap_kaggle/nbs'\n","#pretrain_dir = '/kaggle/input/swin-tiny-small-22k-pretrained/'\n","\n","TRAIN = '/home/lakshita/somusan/hubmap_kaggle/nbs/hubmap-22-aug-pixel-size'\n","LABELS = '/home/lakshita/somusan/hubmap_kaggle/hubmap_data/hubmap-organ-segmentation/train.csv' #only lungs"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005637,"end_time":"2022-08-16T19:03:00.299522","exception":false,"start_time":"2022-08-16T19:03:00.293885","status":"completed"},"tags":[]},"source":["## Utility"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.134400Z","iopub.status.busy":"2022-08-17T06:18:48.131958Z","iopub.status.idle":"2022-08-17T06:18:48.204636Z","shell.execute_reply":"2022-08-17T06:18:48.203398Z","shell.execute_reply.started":"2022-08-17T06:18:48.134356Z"},"papermill":{"duration":0.053647,"end_time":"2022-08-16T19:03:00.359131","exception":false,"start_time":"2022-08-16T19:03:00.305484","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def image_to_tensor(image, mode='bgr'): #image mode\n","    if mode=='bgr':\n","        image = image[:,:,::-1]\n","    x = image\n","    x = x.transpose(2,0,1)\n","    x = np.ascontiguousarray(x)\n","    x = torch.tensor(x, dtype = torch.float)\n","    return x\n","\n","def mask_to_tensor(mask):\n","    x = mask\n","    #x = x.transpose(2, 0, 1)\n","    x = torch.tensor(x, dtype = torch.float)\n","    return x\n","\n","\n","class RGB(nn.Module):\n","    IMAGE_RGB_MEAN = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n","    IMAGE_RGB_STD  = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n","\n","    def __init__(self,):\n","        super(RGB, self).__init__()\n","        self.register_buffer('mean', torch.zeros(1,3,1,1))\n","        self.register_buffer('std', torch.ones(1,3,1,1))\n","        self.mean.data = torch.FloatTensor(self.IMAGE_RGB_MEAN).view(self.mean.shape)\n","        self.std.data = torch.FloatTensor(self.IMAGE_RGB_STD).view(self.std.shape)\n","\n","    def forward(self, x):\n","        x = (x-self.mean)/self.std\n","        return x\n","\n","# def message(mode='print'):\n","#     asterisk = ' '\n","#     if mode==('print'):\n","#         loss = batch_loss\n","#     if mode==('log'):\n","#         loss = train_loss\n","#         if (iteration % iter_save == 0): asterisk = '*'\n","    \n","#     print(\"=---------------------DEBUG\")\n","#     print(loss)\n","#     print()\n","#     print(loss.shape)\n","#     print(\"=---------------------DEBUG\")\n","    \n","#     text = \\\n","#         ('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+') + \\\n","#         '%4.3f  %4.3f   | '%(*valid_loss,) + \\\n","#         '%4.3f  %4.3f | '%(*dict(loss)) + \\\n","#         '%s' % ((time.time() - start_timer))\n","#     return text\n","\n","def message(mode='print'):\n","    asterisk = ' '\n","    if mode==('print'):\n","        loss = batch_loss\n","    if mode==('log'):\n","        loss = train_loss\n","        if (iteration % iter_save == 0): asterisk = '*'\n","\n","    # text = \\\n","    #     ('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+') + \\\n","    #     '%4.3f  %4.3f  %4.4f  %4.3f   | '%(*valid_loss,) + \\\n","    #     )\n","    # print(\"=---------------------DEBUG\")\n","    # print(loss)\n","    # print(loss.shape)\n","    # print(\"=---------------------DEBUG\")\n","    text = f'{rate}  {iteration}, {epoch}  | {round(valid_loss[0], 4)} {round(valid_loss[1], 4)}  \\\n","            |  {round((loss[0]),2)} {round((loss[1]),2)} | {round((time.time() - start_timer), 3)}'\n","    # print(('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+'))\n","    # print('VALID LOSS: %4.3f  %4.3f | '%(*valid_loss,))\n","    # print()\n","    # print('TRAINING LOSS: %4.3f  %4.3f   | '%(*loss,))\n","    # print()\n","    # print('%s' % ((time.time() - start_timer)))\n","    # print('\\n')\n","    return text \n","\n","def rle_decode(mask_rle, shape):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (height,width) of array to return \n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape).T\n","\n","\n","# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n","def rle_encode(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","\n","def get_learning_rate(optimizer):\n","    return optimizer.param_groups[0]['lr']"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005519,"end_time":"2022-08-16T19:03:00.370356","exception":false,"start_time":"2022-08-16T19:03:00.364837","status":"completed"},"tags":[]},"source":["## Augments"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.213072Z","iopub.status.busy":"2022-08-17T06:18:48.210690Z","iopub.status.idle":"2022-08-17T06:18:48.224027Z","shell.execute_reply":"2022-08-17T06:18:48.223000Z","shell.execute_reply.started":"2022-08-17T06:18:48.213032Z"},"papermill":{"duration":0.016754,"end_time":"2022-08-16T19:03:00.392910","exception":false,"start_time":"2022-08-16T19:03:00.376156","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def valid_augment5(image, mask, organ):\n","    #image, mask  = do_crop(image, mask, image_size, xy=(None,None))\n","    return image, mask\n","from numpy.random import choice\n","def train_augment5b(image, mask, organ):\n","    # image, mask = do_random_flip(image, mask)\n","    # image, mask = do_random_rot90(image, mask)\n","    \n","\n","    for fn in np.random.choice([\n","        lambda image, mask: (image, mask),\n","        #lambda image, mask: do_random_noise(image, mask, mag=0.1),\n","        lambda image, mask: do_random_contast(image, mask, mag=0.40),\n","        lambda image, mask: do_random_hsv(image, mask, mag=[0.40, 0.40, 0])\n","    ], 2): image, mask = fn(image, mask)\n","\n","    for fn in np.random.choice([\n","        lambda image, mask: (image, mask),\n","        # lambda image, mask: do_random_rotate_scale(image, mask, angle=45, scale=[0.50, 2.0]),\n","    ], 1): image, mask = fn(image, mask)\n","\n","    return image, mask"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.229868Z","iopub.status.busy":"2022-08-17T06:18:48.229470Z","iopub.status.idle":"2022-08-17T06:18:48.258454Z","shell.execute_reply":"2022-08-17T06:18:48.257422Z","shell.execute_reply.started":"2022-08-17T06:18:48.229830Z"},"papermill":{"duration":0.024978,"end_time":"2022-08-16T19:03:00.423769","exception":false,"start_time":"2022-08-16T19:03:00.398791","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def do_random_flip(image, mask):\n","    if np.random.rand()>0.5:\n","        image = cv2.flip(image,0)\n","        mask = cv2.flip(mask,0)\n","    if np.random.rand()>0.5:\n","        image = cv2.flip(image,1)\n","        mask = cv2.flip(mask,1)\n","    if np.random.rand()>0.5:\n","        image = image.transpose(1,0,2)\n","        mask = mask.transpose(1,0)\n","    \n","    image = np.ascontiguousarray(image)\n","    mask = np.ascontiguousarray(mask)\n","    return image, mask\n","\n","def do_random_rot90(image, mask):\n","    r = np.random.choice([\n","        0,\n","        cv2.ROTATE_90_CLOCKWISE,\n","        cv2.ROTATE_90_COUNTERCLOCKWISE,\n","        cv2.ROTATE_180,\n","    ])\n","    if r==0:\n","        return image, mask\n","    else:\n","        image = cv2.rotate(image, r)\n","        mask = cv2.rotate(mask, r)\n","        return image, mask\n","    \n","def do_random_contast(image, mask, mag=0.3): #this thing kills the image and sets all pixels to 1\n","    alpha = 1 + random.uniform(-1,1)*mag\n","    image = image * alpha\n","    image = np.clip(image,0,1)\n","    return image, mask\n","\n","def do_random_hsv(image, mask, mag=[0.15,0.25,0.25]):\n","    image = (image*255).astype(np.uint8)\n","    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","\n","    h = hsv[:, :, 0].astype(np.float32)  # hue\n","    s = hsv[:, :, 1].astype(np.float32)  # saturation\n","    v = hsv[:, :, 2].astype(np.float32)  # value\n","    h = (h*(1 + random.uniform(-1,1)*mag[0]))%180\n","    s =  s*(1 + random.uniform(-1,1)*mag[1])\n","    v =  v*(1 + random.uniform(-1,1)*mag[2])\n","\n","    hsv[:, :, 0] = np.clip(h,0,180).astype(np.uint8)\n","    hsv[:, :, 1] = np.clip(s,0,255).astype(np.uint8)\n","    hsv[:, :, 2] = np.clip(v,0,255).astype(np.uint8)\n","    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","    image = image.astype(np.float32)/255\n","    return image, mask\n","\n","def do_random_noise(image, mask, mag=0.1): #also seems to kill the image and set to 1\n","    height, width = image.shape[:2]\n","    noise = np.random.uniform(-1,1, (height, width,1))*mag\n","    image = image + noise\n","    image = np.clip(image,0,1)\n","    return image, mask\n","\n","def do_random_rotate_scale(image, mask, angle=30, scale=[0.8,1.2] ):\n","    angle = np.random.uniform(-angle, angle)\n","    scale = np.random.uniform(*scale) if scale is not None else 1\n","    \n","    height, width = image.shape[:2]\n","    center = (height // 2, width // 2)\n","    \n","    transform = cv2.getRotationMatrix2D(center, angle, scale)\n","    image = cv2.warpAffine( image, transform, (width, height), flags=cv2.INTER_LINEAR,\n","                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n","    mask  = cv2.warpAffine( mask, transform, (width, height), flags=cv2.INTER_LINEAR,\n","                            borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n","    return image, mask\n","\n","\n","# image = cv2.imread(\"/home/lakshita/somusan/hubmap_kaggle/hubmap_data/hubmap-organ-segmentation/train_images/686.tiff\")\n","# mask = cv2.imread(\"/home/lakshita/somusan/hubmap_kaggle/hubmap_data/mask_png/train_binary_masks/686.png\",0)\n","# aug_img, aug_mask = do_random_rotate_scale(image, mask)\n","\n","\n","# plt.figure(figsize=(16,18))\n","# plt.subplot(1,2,1)\n","# plt.imshow(aug_img)\n","\n","# plt.subplot(1,2,2)\n","# plt.imshow(aug_mask)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.266794Z","iopub.status.busy":"2022-08-17T06:18:48.263553Z","iopub.status.idle":"2022-08-17T06:18:48.273504Z","shell.execute_reply":"2022-08-17T06:18:48.272295Z","shell.execute_reply.started":"2022-08-17T06:18:48.266744Z"},"papermill":{"duration":0.012714,"end_time":"2022-08-16T19:03:00.442141","exception":false,"start_time":"2022-08-16T19:03:00.429427","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# dummy_mask = np.zeros( (2023, 2023, 1) )\n","# dummy_mask[ dummy_mask.shape[0] // 2 : dummy_mask.shape[0] // 2 + 100, \n","#            dummy_mask.shape[0] // 2 : dummy_mask.shape[0] // 2 + 100] = 1\n","# # dummy_mask[150 : 170, 220 : 240] = 1\n","# # dummy_mask[300 : 320, 150 : 170] = 1\n","# dummy_mask[1000 : 1100, 450 : 550] = 1\n","# dummy_mask[1300 : 1400, 500 : 600] = 1\n","# dummy_mask[1100 : 1200, 700 : 800] = 1\n","# dummy_mask[800 : 900, 1000 : 1100] = 1\n","# dummy_mask[1350 : 1450, 1250 : 1350] = 1\n","\n","# plt.imshow(dummy_mask)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005493,"end_time":"2022-08-16T19:03:00.454279","exception":false,"start_time":"2022-08-16T19:03:00.448786","status":"completed"},"tags":[]},"source":["## Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.281438Z","iopub.status.busy":"2022-08-17T06:18:48.278764Z","iopub.status.idle":"2022-08-17T06:18:48.300202Z","shell.execute_reply":"2022-08-17T06:18:48.298987Z","shell.execute_reply.started":"2022-08-17T06:18:48.281400Z"},"papermill":{"duration":0.02051,"end_time":"2022-08-16T19:03:00.480870","exception":false,"start_time":"2022-08-16T19:03:00.460360","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["image_size = 512 #1024 #512 #512\n","\n","class HubmapDataset(Dataset):\n","    def __init__(self, df, augment=None):\n","\n","        self.df = df\n","        self.augment = augment\n","        self.length = len(self.df)\n","        self.organ_to_label = {'kidney' : 0,\n","                               'prostate' : 1,\n","                               'largeintestine' : 2,\n","                               'spleen' : 3,\n","                               'lung' : 4}\n","\n","    def __str__(self):\n","        string = ''\n","        string += '\\tlen = %d\\n' % len(self)\n","\n","        d = self.df.organ.value_counts().to_dict()\n","        for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n","            string +=  '%24s %3d (%0.3f) \\n'%(k, d.get(k,0), d.get(k,0)/len(self.df))\n","        return string\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, index):\n","        d = self.df.iloc[index]\n","        img_height = self.df.loc[index, 'img_height']\n","        img_width = self.df.loc[index, 'img_width']\n","        organ = self.organ_to_label[d.organ]\n","\n","        image = cv2.cvtColor(cv2.imread(os.path.join(TRAIN, f'{d.id}.png')), cv2.COLOR_BGR2RGB)\n","        \n","        rle_mask = self.df.loc[index, 'rle']\n","        mask = rle_decode(rle_mask, (img_height, img_width))\n","        #mask = cv2.cvtColor(mask, cv2.IMREAD_GRAYSCALE)\n","        #mask = cv2.imread(os.path.join(MASKS,fname),cv2.IMREAD_GRAYSCALE)\n","        # mask = np.expand_dims(mask, axis = 2)\n","        # print(mask.shape)\n","        \n","        image = image.astype(np.float32)/255\n","        #mask  = mask.astype(np.float32)/255\n","        mask = mask.astype(np.float32)\n","\n","        s = d.pixel_size/0.4 * (image_size/3000)\n","        image = cv2.resize(image,dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n","        mask  = cv2.resize(mask, dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n","\n","        if self.augment is not None:\n","            image, mask = self.augment(image, mask, organ)\n","\n","        mask = np.expand_dims(mask, axis = 0)\n","\n","        r ={}\n","        r['index']= index\n","        r['organ'] = torch.tensor([organ], dtype=torch.long)\n","        r['image'] = image_to_tensor(image)\n","        r['mask' ] = mask_to_tensor(mask)\n","        return r"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.307774Z","iopub.status.busy":"2022-08-17T06:18:48.305096Z","iopub.status.idle":"2022-08-17T06:18:48.316642Z","shell.execute_reply":"2022-08-17T06:18:48.315454Z","shell.execute_reply.started":"2022-08-17T06:18:48.307736Z"},"papermill":{"duration":0.01215,"end_time":"2022-08-16T19:03:00.498755","exception":false,"start_time":"2022-08-16T19:03:00.486605","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 512, 512])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"/home/lakshita/somusan/hubmap_kaggle/hubmap_data/hubmap-organ-segmentation/train.csv\")\n","ds = HubmapDataset(df)\n","\n","ds[10]['mask'].shape"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00545,"end_time":"2022-08-16T19:03:00.509765","exception":false,"start_time":"2022-08-16T19:03:00.504315","status":"completed"},"tags":[]},"source":["## Model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.324964Z","iopub.status.busy":"2022-08-17T06:18:48.321812Z","iopub.status.idle":"2022-08-17T06:18:48.389832Z","shell.execute_reply":"2022-08-17T06:18:48.388678Z","shell.execute_reply.started":"2022-08-17T06:18:48.324925Z"},"papermill":{"duration":0.049669,"end_time":"2022-08-16T19:03:00.565172","exception":false,"start_time":"2022-08-16T19:03:00.515503","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class FPN(nn.Module):\n","    def __init__(self, input_channels:list, output_channels:list):\n","        super().__init__()\n","        self.convs = nn.ModuleList(\n","            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n","             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n","             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n","            for in_ch, out_ch in zip(input_channels, output_channels)])\n","        \n","    def forward(self, xs:list, last_layer):\n","        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear') \n","               for i,(c,x) in enumerate(zip(self.convs, xs))]\n","        hcs.append(last_layer)\n","        return torch.cat(hcs, dim=1)\n","\n","class UnetBlock(nn.Module):\n","    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n","                 self_attention:bool=False, **kwargs):\n","        super().__init__()\n","        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n","        self.bn = nn.BatchNorm2d(x_in_c)\n","        ni = up_in_c//2 + x_in_c\n","        nf = nf if nf is not None else max(up_in_c//2,32)\n","        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n","        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n","            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n","        s = left_in\n","        up_out = self.shuf(up_in)\n","        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n","        return self.conv2(self.conv1(cat_x))\n","        \n","class _ASPPModule(nn.Module):\n","    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n","        super().__init__()\n","        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n","                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n","        self.bn = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU()\n","\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x = self.atrous_conv(x)\n","        x = self.bn(x)\n","\n","        return self.relu(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class ASPP(nn.Module):\n","    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None):\n","        super().__init__()\n","        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n","            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n","        self.aspps = nn.ModuleList(self.aspps)\n","        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n","                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n","                        nn.BatchNorm2d(mid_c), nn.ReLU())\n","        out_c = out_c if out_c is not None else mid_c\n","        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n","                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n","        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x0 = self.global_pool(x)\n","        xs = [aspp(x) for aspp in self.aspps]\n","        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n","        x = torch.cat([x0] + xs, dim=1)\n","        return self.out_conv(x)\n","    \n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class config:\n","    pretrained_root = '/home/lakshita/somusan/hubmap_kaggle/nbs/efficientnet-pytorch/'\n","    efficient_net_encoders = {\n","        \"efficientnet-b0\": {\n","            \"out_channels\": (3, 32, 24, 40, 112, 320),\n","            \"stage_idxs\": (3, 5, 9, 16),\n","            \"weight_path\": pretrained_root + \"efficientnet-b0-08094119.pth\"\n","        },\n","        \"efficientnet-b1\": {\n","            \"out_channels\": (3, 32, 24, 40, 112, 320),\n","            \"stage_idxs\": (5, 8, 16, 23),\n","            \"weight_path\": pretrained_root + \"efficientnet-b1-dbc7070a.pth\"\n","        },\n","        \"efficientnet-b2\": {\n","            \"out_channels\": (3, 32, 24, 48, 120, 352),\n","            \"stage_idxs\": (5, 8, 16, 23),\n","            \"weight_path\": pretrained_root + \"efficientnet-b2-27687264.pth\"\n","        },\n","        \"efficientnet-b3\": {\n","            \"out_channels\": (3, 40, 32, 48, 136, 384),\n","            \"stage_idxs\": (5, 8, 18, 26),\n","            \"weight_path\": pretrained_root + \"efficientnet-b3-c8376fa2.pth\"\n","        },\n","        \"efficientnet-b4\": {\n","            \"out_channels\": (3, 48, 32, 56, 160, 448),\n","            \"stage_idxs\": (6, 10, 22, 32),\n","            \"weight_path\": pretrained_root + \"efficientnet-b4-e116e8b3.pth\"\n","        },\n","        \"efficientnet-b5\": {\n","            \"out_channels\": (3, 48, 40, 64, 176, 512),\n","            \"stage_idxs\": (8, 13, 27, 39),\n","            \"weight_path\": pretrained_root + \"efficientnet-b5-586e6cc6.pth\"\n","        },\n","        \"efficientnet-b6\": {\n","            \"out_channels\": (3, 56, 40, 72, 200, 576),\n","            \"stage_idxs\": (9, 15, 31, 45),\n","            \"weight_path\": pretrained_root + \"efficientnet-b6-c76e70fd.pth\"\n","        },\n","        \"efficientnet-b7\": {\n","            \"out_channels\": (3, 64, 48, 80, 224, 640),\n","            \"stage_idxs\": (11, 18, 38, 55),\n","            \"weight_path\": pretrained_root + \"efficientnet-b7-dcc49843.pth\"\n","        }\n","    }\n","    model = 'efficientnet-b7'\n","    \n","class EfficientNetEncoder(EfficientNet):\n","    def __init__(self, stage_idxs, out_channels, model_name, depth=5):\n","\n","        blocks_args, global_params = get_model_params(model_name, override_params=None)\n","        super().__init__(blocks_args, global_params)\n","        \n","        cfg = config.efficient_net_encoders[model_name]\n","\n","        self._stage_idxs = stage_idxs\n","        self._out_channels = out_channels\n","        self._depth = depth\n","        self._in_channels = 3\n","\n","        del self._fc\n","        self.load_state_dict(torch.load(cfg['weight_path']))\n","\n","    def get_stages(self):\n","        return [\n","            nn.Identity(),\n","            nn.Sequential(self._conv_stem, self._bn0, self._swish),\n","            self._blocks[:self._stage_idxs[0]],\n","            self._blocks[self._stage_idxs[0]:self._stage_idxs[1]],\n","            self._blocks[self._stage_idxs[1]:self._stage_idxs[2]],\n","            self._blocks[self._stage_idxs[2]:],\n","        ]\n","\n","    def forward(self, x):\n","        stages = self.get_stages()\n","\n","        block_number = 0.\n","        drop_connect_rate = self._global_params.drop_connect_rate\n","\n","        features = []\n","        for i in range(self._depth + 1):\n","\n","            # Identity and Sequential stages\n","            if i < 2:\n","                x = stages[i](x)\n","\n","            # Block stages need drop_connect rate\n","            else:\n","                for module in stages[i]:\n","                    drop_connect = drop_connect_rate * block_number / len(self._blocks)\n","                    block_number += 1.\n","                    x = module(x, drop_connect)\n","\n","            features.append(x)\n","\n","        return features\n","\n","    def load_state_dict(self, state_dict, **kwargs):\n","        state_dict.pop(\"_fc.bias\")\n","        state_dict.pop(\"_fc.weight\")\n","        super().load_state_dict(state_dict, **kwargs)  \n","        \n","\n","class EffUnet(nn.Module):\n","    def __init__(self, model_name, stride=1):\n","        super().__init__()\n","        self.focal_loss = FocalLoss()\n","        cfg = config.efficient_net_encoders[model_name]\n","        stage_idxs = cfg['stage_idxs']\n","        out_channels = cfg['out_channels']\n","        \n","        self.encoder = EfficientNetEncoder(stage_idxs, out_channels, model_name)\n","\n","        #aspp with customized dilatations\n","        self.aspp = ASPP(out_channels[-1], 256, out_c=384, \n","                         dilations=[stride*1, stride*2, stride*3, stride*4])\n","        self.drop_aspp = nn.Dropout2d(0.5)\n","        #decoder\n","        self.dec4 = UnetBlock(384, out_channels[-2], 256)\n","        self.dec3 = UnetBlock(256, out_channels[-3], 128)\n","        self.dec2 = UnetBlock(128, out_channels[-4], 64)\n","        self.dec1 = UnetBlock(64, out_channels[-5], 32)\n","        self.fpn = FPN([384, 256, 128, 64], [16]*4)\n","        self.drop = nn.Dropout2d(0.1)\n","        self.final_conv = ConvLayer(32+16*4, 1, ks=1, norm_type=None, act_cls=None)\n","        \n","        self.rgb = RGB()\n","        \n","    def forward(self, batch):\n","        x = batch['image']\n","        B, C, H, W = x.shape\n","        x = self.rgb(x)\n","        enc0, enc1, enc2, enc3, enc4 = self.encoder(x)[-5:]\n","        enc5 = self.aspp(enc4)\n","        dec3 = self.dec4(self.drop_aspp(enc5), enc3)\n","        dec2 = self.dec3(dec3,enc2)\n","        dec1 = self.dec2(dec2,enc1)\n","        dec0 = self.dec1(dec1,enc0)\n","        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n","        x = self.final_conv(self.drop(x))\n","        x = F.interpolate(x, size = 512, mode='bilinear', align_corners=False)\n","\n","\n","        # print(\"s shape\",x.shape)\n","        output = {}\n","        # if 'loss' in self.output_type:\n","        output['bce_loss'] = F.binary_cross_entropy_with_logits(x,batch['mask'])\n","        # for i in range(4):\n","        #     output['aux%d_loss'%i] = criterion_aux_loss(self.aux[i](decoder[i]),batch['mask'])\n","        output['focal_loss'] = self.focal_loss(x,batch['mask'])\n","        # print(output)\n","        # if 'inference' in self.output_type:\n","        #     output['probability'] = torch.sigmoid(x)\n","        return x, output"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.396725Z","iopub.status.busy":"2022-08-17T06:18:48.394407Z","iopub.status.idle":"2022-08-17T06:18:48.402394Z","shell.execute_reply":"2022-08-17T06:18:48.401227Z","shell.execute_reply.started":"2022-08-17T06:18:48.396687Z"},"papermill":{"duration":0.013343,"end_time":"2022-08-16T19:03:00.584292","exception":false,"start_time":"2022-08-16T19:03:00.570949","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# FOCAL LOSS ----------------\n","ALPHA = 0.8\n","GAMMA = 2\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","#         inputs = F.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        #first compute binary cross-entropy \n","        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n","        BCE_EXP = torch.exp(-BCE)\n","        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n","                       \n","        return focal_loss"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def run_check_net():\n","    batch_size = 2\n","    image_size = 768 #512\n","\n","    #---\n","    batch = {\n","        'image' : torch.from_numpy( np.random.uniform(-1,1,(batch_size,3,image_size,image_size)) ).float(),\n","        'mask'  : torch.from_numpy( np.random.choice(2,(batch_size,1,image_size,image_size)) ).float(),\n","        'organ' : torch.from_numpy( np.random.choice(5,(batch_size)) ).long(),\n","    }\n","    batch = {k:v.cuda() for k,v in batch.items()}\n","\n","    net = EffUnet(config.model).cuda()\n","    # net.load_pretrain()\n","\n","    with torch.no_grad():\n","        with torch.cuda.amp.autocast(enabled=True):\n","            output, loss = net(batch)\n","\n","    print('batch')\n","    for k,v in batch.items():\n","        print('%32s :'%k, v.shape)\n","\n","    print('output')\n","    print(output.shape)\n","    print(loss['bce_loss'])\n","    print(loss['focal_loss'])\n","\n","    \n","    # for k,v in output.items():\n","    #     if 'loss' not in k:\n","    #         print('%32s :'%k, v.shape)\n","    # for k,v in output.items():\n","    #     if 'loss' in k:\n","    #         print('%32s :'%k, v.item())\n","\n","# run_check_net()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00547,"end_time":"2022-08-16T19:03:00.617292","exception":false,"start_time":"2022-08-16T19:03:00.611822","status":"completed"},"tags":[]},"source":["## Folds"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.429843Z","iopub.status.busy":"2022-08-17T06:18:48.426734Z","iopub.status.idle":"2022-08-17T06:18:48.443398Z","shell.execute_reply":"2022-08-17T06:18:48.442495Z","shell.execute_reply.started":"2022-08-17T06:18:48.429803Z"},"papermill":{"duration":0.017484,"end_time":"2022-08-16T19:03:00.640381","exception":false,"start_time":"2022-08-16T19:03:00.622897","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def make_fold(fold = 3):\n","    df = pd.read_csv(LABELS)\n","    df = df[df['organ'] == 'lung']\n","    print(len(df))\n","\n","    num_fold =48\n","    skf = KFold(n_splits = num_fold, shuffle = True,random_state = 42)\n","\n","    df.loc[:,'fold']=-1\n","    for f,(t_idx, v_idx) in enumerate(skf.split(X=df['id'], y=df['organ'])):\n","        df.iloc[v_idx,-1]=f\n","\n","    #check\n","    if 0:\n","        for f in range(num_fold):\n","            train_df=df[df.fold!=f].reset_index(drop=True)\n","            valid_df=df[df.fold==f].reset_index(drop=True)\n","\n","            print('fold %d'%f)\n","            t = train_df.organ.value_counts().to_dict()\n","            v = valid_df.organ.value_counts().to_dict()\n","            for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n","                print('%32s %3d (%0.3f)  %3d (%0.3f)'%(k,t.get(k,0),t.get(k,0)/len(train_df),v.get(k,0),v.get(k,0)/len(valid_df)))\n","\n","            print('')\n","            zz=0\n","\n","    train_df=df[df.fold!=fold].reset_index(drop=True)\n","    valid_df=df[df.fold==fold].reset_index(drop=True)\n","    return train_df,valid_df"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005895,"end_time":"2022-08-16T19:03:00.651958","exception":false,"start_time":"2022-08-16T19:03:00.646063","status":"completed"},"tags":[]},"source":["## Competition metric"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.454933Z","iopub.status.busy":"2022-08-17T06:18:48.452286Z","iopub.status.idle":"2022-08-17T06:18:48.463652Z","shell.execute_reply":"2022-08-17T06:18:48.462634Z","shell.execute_reply.started":"2022-08-17T06:18:48.454894Z"},"papermill":{"duration":0.013577,"end_time":"2022-08-16T19:03:00.671364","exception":false,"start_time":"2022-08-16T19:03:00.657787","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def compute_dice_score(probability, mask, smooth = 1):\n","    N = len(probability)\n","    p = probability.reshape(N,-1)\n","    t = mask.reshape(N,-1)\n","\n","    p = p>0.5\n","    t = t>0.5\n","    uion = p.sum(-1) + t.sum(-1)\n","    overlap = (p*t).sum(-1)\n","    dice = 2*overlap/(uion+0.0001)\n","    return dice"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.005378,"end_time":"2022-08-16T19:03:00.682366","exception":false,"start_time":"2022-08-16T19:03:00.676988","status":"completed"},"tags":[]},"source":["## Validation"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.471856Z","iopub.status.busy":"2022-08-17T06:18:48.468907Z","iopub.status.idle":"2022-08-17T06:18:48.486188Z","shell.execute_reply":"2022-08-17T06:18:48.485069Z","shell.execute_reply.started":"2022-08-17T06:18:48.471796Z"},"papermill":{"duration":0.01812,"end_time":"2022-08-16T19:03:00.706195","exception":false,"start_time":"2022-08-16T19:03:00.688075","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def validate(net, valid_loader, debug = False):\n","    \n","    valid_num = 0\n","    valid_probability = []\n","    valid_mask = []\n","    valid_loss = 0\n","    \n","    criterion = nn.BCEWithLogitsLoss()\n","    \n","    net = net.eval()\n","    start_timer = time.time()\n","    \n","    for t, batch in enumerate(valid_loader):\n","        \n","        with torch.no_grad():\n","            with amp.autocast(enabled = is_amp):\n","                \n","                batch_size = len(batch['index'])\n","                batch['image'] = batch['image'].cuda()\n","                batch['mask' ] = batch['mask' ].cuda()\n","                batch['organ'] = batch['organ'].cuda()\n","\n","                output, loss = net(batch)\n","                loss0 = loss['bce_loss'].mean()\n","                # batch['mask'] = batch['mask']\n","                # loss = criterion(output, batch['mask'])\n","\n","        valid_probability.append(output.data.cpu().numpy())\n","        valid_mask.append(batch['mask'].data.cpu().numpy())\n","        valid_num += batch_size\n","        valid_loss += batch_size * loss0.item()\n","        \n","        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),(time.time() - start_timer)),end='',flush=True)\n","    \n","    assert(valid_num == len(valid_loader.dataset))\n","\n","    probability = np.concatenate(valid_probability)\n","    mask = np.concatenate(valid_mask)\n","\n","    loss = valid_loss/valid_num\n","\n","    dice = compute_dice_score(probability, mask)\n","    dice = dice.mean()\n","    \n","    return [dice, loss]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","df_lung = df[df['organ']=='lung']\n","train_df_, valid_df_ = train_test_split(df_lung, test_size=0.1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00551,"end_time":"2022-08-16T19:03:00.717363","exception":false,"start_time":"2022-08-16T19:03:00.711853","status":"completed"},"tags":[]},"source":["## Initialize"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:48.494186Z","iopub.status.busy":"2022-08-17T06:18:48.491148Z","iopub.status.idle":"2022-08-17T06:18:57.748016Z","shell.execute_reply":"2022-08-17T06:18:57.746853Z","shell.execute_reply.started":"2022-08-17T06:18:48.494147Z"},"papermill":{"duration":8.210001,"end_time":"2022-08-16T19:03:08.932978","exception":false,"start_time":"2022-08-16T19:03:00.722977","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["48\n","numper of training and validation samples 47 1\n"]}],"source":["CFG = {\n","    'fold_num': 5,\n","    'seed': 719,\n","    'model_arch': 'tf_efficientnet_b4_ns',\n","    'img_size': 512,\n","    'epochs': 10,\n","    'train_bs': 16,\n","    'valid_bs': 32,\n","    'T_0': 10,\n","    'lr': 1e-4,\n","    'min_lr': 1e-6,\n","    'weight_decay':1e-6,\n","    'num_workers': 4,\n","    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n","    'verbose_step': 1,\n","    'device': 'cuda:0'\n","}\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","fold = 0\n","\n","out_dir = root_dir + '/result/effnetb7/focal-fold-%d' % (fold)\n","initial_checkpoint = None\n","\n","start_lr = 5e-5\n","batch_size = 4\n","\n","## setup  ----------------------------------------\n","for f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n","\n","    \n","log = open(out_dir+'/log.train.txt',mode='a')\n","log.write('\\n--- [START %s] %s\\n\\n' % ('EfficientNet-b7', '-' * 64))\n","log.write('\\n')\n","\n","## dataset ----------------------------------------\n","log.write('** dataset setting **\\n')\n","\n","\n","train_df, valid_df = make_fold(fold) #train_df_, valid_df_ #make_fold(fold)\n","print(\"numper of training and validation samples\",len(train_df), len(valid_df))\n","\n","train_dataset = HubmapDataset(train_df, train_augment5b)\n","valid_dataset = HubmapDataset(valid_df, valid_augment5)\n","\n","# train_loader = torch.utils.data.DataLoader(\n","#                dataset=train_dataset,\n","#                batch_size=batch_size,\n","#                shuffle=False,\n","#                num_workers=8,\n","#                drop_last   = True)\n","\n","train_loader  = DataLoader(\n","    train_dataset,\n","    sampler = RandomSampler(train_dataset),\n","    batch_size  = batch_size,\n","    drop_last   = False,\n","    num_workers = 8,\n","    pin_memory  = False,\n","    worker_init_fn = lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id)\n",")\n","\n","valid_loader = DataLoader(\n","    valid_dataset,\n","    sampler = SequentialSampler(valid_dataset),\n","    batch_size  = batch_size,\n","    drop_last   = False,\n","    num_workers = 4,\n","    pin_memory  = False\n",")\n","\n","\n","log.write('fold = %s\\n'%str(fold))\n","log.write('train_dataset : \\n%s\\n'%(train_dataset))\n","log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n","log.write('\\n')\n","\n","\n","## net ----------------------------------------\n","log.write('** net setting **\\n')\n","\n","scaler = amp.GradScaler(enabled = is_amp)\n","net = EffUnet(config.model).cuda()\n","\n","if initial_checkpoint is not None:\n","    f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n","    start_iteration = f['iteration']\n","    start_epoch = f['epoch']\n","    state_dict  = f['state_dict']\n","    net.load_state_dict(state_dict,strict=False)  #True\n","else:\n","    start_iteration = 0\n","    start_epoch = 0\n","\n","\n","log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n","log.write('\\n')\n","\n","\n","## optimiser ----------------------------------\n","if 0: ##freeze\n","    for p in net.stem.parameters():   p.requires_grad = False\n","    pass\n","\n","def freeze_bn(net):\n","    for m in net.modules():\n","        if isinstance(m, nn.BatchNorm2d):\n","            m.eval()\n","            m.weight.requires_grad = False\n","            m.bias.requires_grad = False\n","            \n","#freeze_bn(net)\n","\n","#-----------------------------------------------\n","\n","# optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n","# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=start_lr,weight_decay=1e-5)\n","optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n","\n","#optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr), alpha=0.5, k=5)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n","log.write('optimizer\\n  %s\\n'%(optimizer))\n","log.write('\\n')\n","\n","#num_iteration = 1000*len(train_loader)\n","num_iteration = 12000\n","iter_log   = 100 #len(train_loader)*3 #479\n","iter_valid = iter_log\n","iter_save  = iter_log"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# pd.read_csv(\"/home/lakshita/somusan/hubmap_kaggle/nbs/aug_lung_data/only_lung.csv\").__len__()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# next(iter(valid_loader))[\"mask\"].shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# items = next(iter(train_loader))\n","# imgs = items[\"image\"].permute((0, 2, 3, 1))\n","# msks = items[\"mask\"].permute((0,2,3,1))\n","# print(imgs.size(), msks.size())"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# items = next(iter(train_loader))\n","# imgs = items[\"image\"].permute((0, 2, 3, 1))\n","# msks = items[\"mask\"].permute((0, 2, 3, 1))\n","# print(imgs.size(), msks.size())\n","\n","# # torch.unique(msks)\n","\n","# import matplotlib.pyplot as plt\n","# def plot_batch(imgs, msks, size=3):\n","#     for idx in range(size):\n","#         plt.figure(figsize=(4*3, 5))\n","\n","#         plt.subplot(1, 3, 1); plt.imshow(imgs[idx])\n","#         plt.title('image', fontsize=15)\n","#         plt.axis('OFF')\n","\n","#         plt.subplot(1, 3, 2); plt.imshow(msks[idx])\n","#         plt.title('mask', fontsize=15)\n","#         plt.axis('OFF')\n","            \n","#         plt.subplot(1, 3, 3); plt.imshow(imgs[idx]); plt.imshow(msks[idx], alpha=0.3)\n","#         plt.title('overlay', fontsize=15)\n","#         plt.axis('OFF')\n","        \n","#         plt.tight_layout()\n","#         plt.show()\n","\n","# plot_batch(imgs, msks, size=3)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.006146,"end_time":"2022-08-16T19:03:08.945358","exception":false,"start_time":"2022-08-16T19:03:08.939212","status":"completed"},"tags":[]},"source":["## Training"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-08-17T06:18:57.755373Z","iopub.status.busy":"2022-08-17T06:18:57.752991Z"},"papermill":{"duration":2131.600859,"end_time":"2022-08-16T19:38:40.552279","exception":false,"start_time":"2022-08-16T19:03:08.951420","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["5e-05  11999, 999.9166666668419  | 0.235 0.1998              |  0.0 0.0 | 7334.885282 0.0 | 6947.11182 | 50.38323934 | 2.8225e-05  100, 8.333333333333323  | 0.0 0.0888              |  0.05000000074505806 0.0 | 64.4765e-05  200, 16.6666666666667  | 0.0 0.0716              |  0.05000000074505806 0.0 | 126.1415e-05  300, 24.999999999999915  | 0.0074 0.0682              |  0.029999999329447746 0.0 | 189.6975e-05  400, 33.33333333333319  | 0.0 0.0836              |  0.019999999552965164 0.0 | 253.0855e-05  500, 41.66666666666676  | 0.0252 0.0718              |  0.03999999910593033 0.0 | 314.6395e-05  600, 50.00000000000033  | 0.0466 0.0905              |  0.009999999776482582 0.0 | 380.8855e-05  700, 58.3333333333339  | 0.1697 0.0843              |  0.009999999776482582 0.0 | 444.2785e-05  800, 66.66666666666724  | 0.1314 0.095              |  0.019999999552965164 0.0 | 506.3285e-05  900, 75.0000000000001  | 0.0495 0.1263              |  0.009999999776482582 0.0 | 570.3425e-05  1000, 83.33333333333296  | 0.1698 0.1204              |  0.009999999776482582 0.0 | 632.9685e-05  1100, 91.66666666666582  | 0.2802 0.0965              |  0.019999999552965164 0.0 | 695.7525e-05  1200, 99.99999999999868  | 0.22 0.1279              |  0.009999999776482582 0.0 | 759.3585e-05  1300, 108.33333333333154  | 0.182 0.1245              |  0.009999999776482582 0.0 | 822.1895e-05  1400, 116.6666666666644  | 0.2167 0.1293              |  0.009999999776482582 0.0 | 885.2765e-05  1500, 124.99999999999726  | 0.1303 0.1711              |  0.009999999776482582 0.0 | 949.925e-05  1600, 133.333333333331  | 0.2348 0.1397              |  0.009999999776482582 0.0 | 1010.8845e-05  1700, 141.6666666666653  | 0.2687 0.1311              |  0.009999999776482582 0.0 | 1069.5485e-05  1800, 149.99999999999957  | 0.3088 0.1301              |  0.0 0.0 | 1130.0125e-05  1900, 158.33333333333385  | 0.1657 0.1426              |  0.0 0.0 | 1188.615e-05  2000, 166.66666666666814  | 0.2227 0.1349              |  0.009999999776482582 0.0 | 1247.5285e-05  2100, 175.00000000000242  | 0.2036 0.1455              |  0.0 0.0 | 1309.2715e-05  2200, 183.3333333333367  | 0.3036 0.1329              |  0.0 0.0 | 1367.9645e-05  2300, 191.66666666667098  | 0.2056 0.1531              |  0.009999999776482582 0.0 | 1425.7225e-05  2400, 200.00000000000526  | 0.2154 0.1616              |  0.0 0.0 | 1486.155e-05  2500, 208.33333333333954  | 0.1927 0.1716              |  0.0 0.0 | 1544.5425e-05  2600, 216.66666666667382  | 0.3606 0.1234              |  0.009999999776482582 0.0 | 1604.0075e-05  2700, 225.0000000000081  | 0.1757 0.166              |  0.0 0.0 | 1663.6365e-05  2800, 233.33333333334238  | 0.3066 0.1546              |  0.009999999776482582 0.0 | 1721.8755e-05  2900, 241.66666666667666  | 0.2936 0.1565              |  0.009999999776482582 0.0 | 1780.7695e-05  3000, 250.00000000001094  | 0.2306 0.1807              |  0.0 0.0 | 1840.875e-05  3100, 258.3333333333444  | 0.2097 0.1969              |  0.0 0.0 | 1899.45e-05  3200, 266.66666666667584  | 0.3556 0.1481              |  0.0 0.0 | 1957.7925e-05  3300, 275.0000000000073  | 0.1896 0.1942              |  0.0 0.0 | 2018.9625e-05  3400, 283.3333333333387  | 0.3327 0.1478              |  0.0 0.0 | 2077.4565e-05  3500, 291.66666666667015  | 0.2776 0.1759              |  0.009999999776482582 0.0 | 2135.5845e-05  3600, 300.0000000000016  | 0.2806 0.1925              |  0.0 0.0 | 2195.9815e-05  3700, 308.33333333333303  | 0.321 0.1663              |  0.0 0.0 | 2254.8165e-05  3800, 316.66666666666447  | 0.3358 0.1799              |  0.0 0.0 | 2312.8415e-05  3900, 324.9999999999959  | 0.174 0.2344              |  0.0 0.0 | 2373.2685e-05  4000, 333.33333333332735  | 0.3523 0.1724              |  0.0 0.0 | 2432.1355e-05  4100, 341.6666666666588  | 0.322 0.1849              |  0.0 0.0 | 2490.2135e-05  4200, 349.9999999999902  | 0.332 0.1792              |  0.0 0.0 | 2550.3145e-05  4300, 358.33333333332166  | 0.1941 0.2085              |  0.0 0.0 | 2609.1695e-05  4400, 366.6666666666531  | 0.3269 0.1753              |  0.0 0.0 | 2667.995e-05  4500, 374.99999999998454  | 0.1951 0.2275              |  0.0 0.0 | 2729.6435e-05  4600, 383.333333333316  | 0.3307 0.1811              |  0.0 0.0 | 2787.8245e-05  4700, 391.6666666666474  | 0.2227 0.1976              |  0.0 0.0 | 2846.0525e-05  4800, 399.99999999997885  | 0.3355 0.1845              |  0.0 0.0 | 2906.4555e-05  4900, 408.3333333333103  | 0.322 0.1941              |  0.0 0.0 | 2965.3245e-05  5000, 416.66666666664173  | 0.3576 0.1896              |  0.0 0.0 | 3024.2835e-05  5100, 424.99999999997317  | 0.201 0.1871              |  0.0 0.0 | 3085.5585e-05  5200, 433.3333333333046  | 0.3053 0.1949              |  0.0 0.0 | 3144.4575e-05  5300, 441.66666666663605  | 0.3306 0.1892              |  0.0 0.0 | 3203.4615e-05  5400, 449.9999999999675  | 0.4004 0.1635              |  0.0 0.0 | 3264.9275e-05  5500, 458.3333333332989  | 0.3683 0.1642              |  0.0 0.0 | 3323.7095e-05  5600, 466.66666666663036  | 0.4046 0.1433              |  0.0 0.0 | 3382.6795e-05  5700, 474.9999999999618  | 0.2907 0.1958              |  0.0 0.0 | 3443.4465e-05  5800, 483.33333333329324  | 0.3546 0.1727              |  0.0 0.0 | 3502.5875e-05  5900, 491.6666666666247  | 0.3495 0.1691              |  0.0 0.0 | 3561.3895e-05  6000, 499.9999999999561  | 0.2244 0.226              |  0.0 0.0 | 3622.1255e-05  6100, 508.33333333328756  | 0.2694 0.2249              |  0.0 0.0 | 3680.2785e-05  6200, 516.6666666666222  | 0.289 0.218              |  0.0 0.0 | 3739.7295e-05  6300, 524.9999999999593  | 0.4161 0.1431              |  0.0 0.0 | 3803.9895e-05  6400, 533.3333333332964  | 0.2891 0.2099              |  0.0 0.0 | 3866.6675e-05  6500, 541.6666666666335  | 0.2188 0.2053              |  0.0 0.0 | 3928.8595e-05  6600, 549.9999999999707  | 0.2432 0.212              |  0.0 0.0 | 3993.3095e-05  6700, 558.3333333333078  | 0.2139 0.2113              |  0.0 0.0 | 4055.5475e-05  6800, 566.6666666666449  | 0.3079 0.202              |  0.0 0.0 | 4116.9085e-05  6900, 574.999999999982  | 0.2755 0.2217              |  0.0 0.0 | 4181.0395e-05  7000, 583.3333333333192  | 0.408 0.146              |  0.0 0.0 | 4243.965e-05  7100, 591.6666666666563  | 0.3366 0.1973              |  0.0 0.0 | 4306.4675e-05  7200, 599.9999999999934  | 0.2872 0.223              |  0.0 0.0 | 4370.8055e-05  7300, 608.3333333333305  | 0.3686 0.1753              |  0.0 0.0 | 4429.9145e-05  7400, 616.6666666666677  | 0.3832 0.1818              |  0.0 0.0 | 4488.0465e-05  7500, 625.0000000000048  | 0.2234 0.2298              |  0.0 0.0 | 4549.0345e-05  7600, 633.3333333333419  | 0.3335 0.1832              |  0.0 0.0 | 4608.3975e-05  7700, 641.666666666679  | 0.3853 0.1791              |  0.0 0.0 | 4666.4465e-05  7800, 650.0000000000161  | 0.2678 0.1994              |  0.0 0.0 | 4727.5355e-05  7900, 658.3333333333533  | 0.3284 0.2017              |  0.0 0.0 | 4786.1695e-05  8000, 666.6666666666904  | 0.251 0.2368              |  0.0 0.0 | 4845.8775e-05  8100, 675.0000000000275  | 0.3469 0.1885              |  0.0 0.0 | 4906.9245e-05  8200, 683.3333333333646  | 0.3587 0.2008              |  0.0 0.0 | 4965.9215e-05  8300, 691.6666666667018  | 0.3614 0.1962              |  0.0 0.0 | 5024.3955e-05  8400, 700.0000000000389  | 0.3525 0.1944              |  0.0 0.0 | 5084.7185e-05  8500, 708.333333333376  | 0.3832 0.1771              |  0.0 0.0 | 5143.2635e-05  8600, 716.6666666667131  | 0.1382 0.2615              |  0.0 0.0 | 5203.6055e-05  8700, 725.0000000000502  | 0.1901 0.263              |  0.0 0.0 | 5264.1785e-05  8800, 733.3333333333874  | 0.2126 0.2497              |  0.0 0.0 | 5324.8525e-05  8900, 741.6666666667245  | 0.1933 0.2636              |  0.0 0.0 | 5388.1875e-05  9000, 750.0000000000616  | 0.2219 0.2563              |  0.0 0.0 | 5452.9955e-05  9100, 758.3333333333987  | 0.2218 0.2573              |  0.0 0.0 | 5515.4355e-05  9200, 766.6666666667359  | 0.2758 0.2185              |  0.0 0.0 | 5579.2875e-05  9300, 775.000000000073  | 0.2689 0.2396              |  0.0 0.0 | 5645.4315e-05  9400, 783.3333333334101  | 0.3652 0.2252              |  0.0 0.0 | 5709.4825e-05  9500, 791.6666666667472  | 0.2844 0.2409              |  0.0 0.0 | 5771.2315e-05  9600, 800.0000000000844  | 0.279 0.248              |  0.0 0.0 | 5835.5855e-05  9700, 808.3333333334215  | 0.2524 0.2592              |  0.0 0.0 | 5897.6355e-05  9800, 816.6666666667586  | 0.342 0.2318              |  0.0 0.0 | 5960.0645e-05  9900, 825.0000000000957  | 0.2755 0.2656              |  0.0 0.0 | 6023.8735e-05  10000, 833.3333333334328  | 0.164 0.3204              |  0.0 0.0 | 6086.2435e-05  10100, 841.66666666677  | 0.2935 0.2189              |  0.0 0.0 | 6147.2615e-05  10200, 850.0000000001071  | 0.3375 0.2271              |  0.0 0.0 | 6211.4035e-05  10300, 858.3333333334442  | 0.3176 0.2438              |  0.0 0.0 | 6274.5645e-05  10400, 866.6666666667813  | 0.303 0.2529              |  0.0 0.0 | 6335.9945e-05  10500, 875.0000000001185  | 0.2911 0.2617              |  0.0 0.0 | 6399.6195e-05  10600, 883.3333333334556  | 0.3162 0.2473              |  0.0 0.0 | 6460.1835e-05  10700, 891.6666666667927  | 0.2922 0.247              |  0.0 0.0 | 6521.0885e-05  10800, 900.0000000001298  | 0.4346 0.1551              |  0.0 0.0 | 6585.0765e-05  10900, 908.333333333467  | 0.4181 0.1811              |  0.0 0.0 | 6647.6135e-05  11000, 916.6666666668041  | 0.3154 0.2475              |  0.0 0.0 | 6709.35e-05  11100, 925.0000000001412  | 0.2936 0.2588              |  0.0 0.0 | 6773.4625e-05  11200, 933.3333333334783  | 0.3849 0.2158              |  0.0 0.0 | 6839.0355e-05  11300, 941.6666666668154  | 0.0143 0.2271              |  0.0 0.0 | 6901.7215e-05  11400, 950.0000000001526  | 0.0987 0.173              |  0.0 0.0 | 6967.4075e-05  11500, 958.3333333334897  | 0.1178 0.1928              |  0.0 0.0 | 7027.9455e-05  11600, 966.6666666668268  | 0.1459 0.1956              |  0.0 0.0 | 7088.3095e-05  11700, 975.0000000001639  | 0.1554 0.1998              |  0.0 0.0 | 7152.1875e-05  11800, 983.3333333335011  | 0.16 0.2115              |  0.0 0.0 | 7214.2685e-05  11900, 991.6666666668382  | 0.235 0.1998              |  0.0 0.0 | 7275.478"]}],"source":["log.write('** start training here! **\\n')\n","log.write('   batch_size = %d \\n'%(batch_size))\n","log.write('                     |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n","log.write('rate     iter  epoch | dice   loss   tp     tn     | loss           | time           \\n')\n","log.write('-------------------------------------------------------------------------------------\\n')\n","\n","valid_loss = np.zeros(4,np.float32)\n","train_loss = np.zeros(2,np.float32)\n","batch_loss = np.zeros_like(train_loss)\n","sum_train_loss = np.zeros_like(train_loss)\n","sum_train = 0\n","\n","start_timer = time.time()\n","iteration = start_iteration\n","epoch = start_epoch\n","rate = 0\n","accum_iter = 4\n","schd_batch_update = False\n","\n","rate = 0\n","mix_proba = 0.4\n","mix_alpha = 0.4\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","while iteration < num_iteration:\n","    for t, batch in enumerate(train_loader):\n","\n","        if iteration%iter_save==0:\n","            if iteration != start_iteration:\n","                torch.save({\n","                    'state_dict': net.state_dict(),\n","                    'iteration': iteration,\n","                    'epoch': epoch,\n","                }, out_dir + '/checkpoint/%08d.model.pth' %  (iteration))\n","                pass\n","\n","\n","        if (iteration%iter_valid==0):\n","            valid_loss = validate(net, valid_loader)\n","            pass\n","\n","\n","        if (iteration%iter_log==0) or (iteration%iter_valid==0):\n","            print('\\r', end='', flush=True)\n","            log.write(message(mode='log') + '\\n')\n","\n","\n","        # learning rate schduler ------------\n","        rate = get_learning_rate(optimizer)\n","\n","        # one iteration update  -------------\n","        batch_size = len(batch['index'])\n","        \n","        #print(batch_size, iteration, epoch)\n","        batch['image'] = batch['image'].half().cuda()\n","        batch['mask' ] = batch['mask' ].half().cuda()\n","        batch['organ'] = batch['organ'].cuda()\n","\n","\n","        net.train()\n","        net.output_type = ['loss']\n","        # if 1:\n","        #     with amp.autocast(enabled = is_amp):\n","        #         output = net(batch)\n","        #         batch['mask'] = batch['mask']\n","        #         loss = criterion(output, batch['mask'])\n","        #         loss = loss / accum_iter \n","                \n","            \n","        #     scaler.scale(loss).backward()\n","\n","            \n","            \n","        #     if ((t + 1) % accum_iter == 0) or (t + 1 == len(train_loader)):\n","        #         scaler.unscale_(optimizer)\n","        #         scaler.step(optimizer)\n","        #         scaler.update()\n","        #         optimizer.zero_grad()\n","        #         if scheduler is not None and schd_batch_update:\n","        #             scheduler.step()\n","\n","        net.train()\n","        net.output_type = ['loss']\n","        if 1:\n","            with amp.autocast(enabled = is_amp):\n","                output, loss_ = net(batch)\n","                loss0  = loss_['bce_loss'].mean()\n","                loss1  = loss_['focal_loss'].mean()\n","\n","            loss = loss0+0.2*loss1\n","\n","            optimizer.zero_grad()\n","            scaler.scale(loss).backward()\n","\n","            scaler.unscale_(optimizer)\n","            scaler.step(optimizer)\n","            scaler.update()\n","           \n","\n","        # print statistics  --------\n","        # batch_loss = loss.item()\n","        batch_loss[:2] = [loss0.item(),loss1.item()]\n","        sum_train_loss += batch_loss\n","        sum_train += 1\n","        if t % 100 == 0:\n","            train_loss = sum_train_loss / (sum_train + 1e-12)\n","            sum_train_loss = 0\n","            sum_train = 0\n","\n","        print('\\r', end='', flush=True)\n","        print(message(mode='print'), end='', flush=True)\n","        epoch += 1 / len(train_loader)\n","        iteration += 1\n","    \n","    torch.cuda.empty_cache()\n","    \n","log.write('\\n')\n","log.close()"]},{"cell_type":"markdown","metadata":{},"source":["### valid_loss\n","- comp data\n","- ~~mask data~~ \n","- effnet data\n","- "]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.0 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"vscode":{"interpreter":{"hash":"21a2a557654fc1676068684031cf9bb9dfda94e124d3623f4e9c9ed764d794ac"}}},"nbformat":4,"nbformat_minor":4}

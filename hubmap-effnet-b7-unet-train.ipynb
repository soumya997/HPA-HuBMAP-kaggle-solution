{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"papermill":{"duration":0.007246,"end_time":"2022-08-16T19:02:52.302567","exception":false,"start_time":"2022-08-16T19:02:52.295321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport time\nimport random\n\nimport torch\nfrom torch import nn\nimport torch.cuda.amp as amp\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import RandomSampler \nfrom torch.utils.data import SequentialSampler\nimport torch.nn.functional as F\nfrom torchmetrics.functional import dice_score\nfrom torch.optim.lr_scheduler import StepLR\nimport tifffile\nfrom fastai.vision.all import *\n\nfrom collections import defaultdict\n\nimport torch\nfrom torch.optim.optimizer import Optimizer\nimport itertools as it\n\nis_amp = True\nimport logging\nimport pandas as pd\nfrom sklearn.model_selection import KFold\n\nimport numpy as np\nfrom itertools import repeat\nimport collections.abc\nimport math\nimport torch\nfrom torch.optim.optimizer import Optimizer, required\nfrom collections import defaultdict\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\n\nsys.path.append('../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master')\n\nfrom efficientnet_pytorch import EfficientNet\nfrom efficientnet_pytorch.utils import url_map, url_map_advprop, get_model_params","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.945852,"end_time":"2022-08-16T19:02:58.254572","exception":false,"start_time":"2022-08-16T19:02:52.308720","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:02.212157Z","iopub.execute_input":"2022-08-19T09:29:02.213344Z","iopub.status.idle":"2022-08-19T09:29:06.738814Z","shell.execute_reply.started":"2022-08-19T09:29:02.213224Z","shell.execute_reply":"2022-08-19T09:29:06.737612Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Directory","metadata":{"papermill":{"duration":0.005742,"end_time":"2022-08-16T19:02:58.266495","exception":false,"start_time":"2022-08-16T19:02:58.260753","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!mkdir /kaggle/working/result\n!mkdir /kaggle/working/checkpoint\n\nroot_dir = '/kaggle/working/'\n#pretrain_dir = '/kaggle/input/swin-tiny-small-22k-pretrained/'\n\nTRAIN = '../input/hubmap-organ-segmentation/train_images'\nLABELS = '../input/hubmap-organ-segmentation/train.csv'","metadata":{"papermill":{"duration":2.014493,"end_time":"2022-08-16T19:03:00.286680","exception":false,"start_time":"2022-08-16T19:02:58.272187","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:06.741255Z","iopub.execute_input":"2022-08-19T09:29:06.742279Z","iopub.status.idle":"2022-08-19T09:29:08.699072Z","shell.execute_reply.started":"2022-08-19T09:29:06.742234Z","shell.execute_reply":"2022-08-19T09:29:08.697766Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Utility","metadata":{"papermill":{"duration":0.005637,"end_time":"2022-08-16T19:03:00.299522","exception":false,"start_time":"2022-08-16T19:03:00.293885","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def image_to_tensor(image, mode='bgr'): #image mode\n    if mode=='bgr':\n        image = image[:,:,::-1]\n    x = image\n    x = x.transpose(2,0,1)\n    x = np.ascontiguousarray(x)\n    x = torch.tensor(x, dtype = torch.float)\n    return x\n\ndef mask_to_tensor(mask):\n    x = mask\n    #x = x.transpose(2, 0, 1)\n    x = torch.tensor(x, dtype = torch.float)\n    return x\n\n\nclass RGB(nn.Module):\n    IMAGE_RGB_MEAN = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n    IMAGE_RGB_STD  = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n\n    def __init__(self,):\n        super(RGB, self).__init__()\n        self.register_buffer('mean', torch.zeros(1,3,1,1))\n        self.register_buffer('std', torch.ones(1,3,1,1))\n        self.mean.data = torch.FloatTensor(self.IMAGE_RGB_MEAN).view(self.mean.shape)\n        self.std.data = torch.FloatTensor(self.IMAGE_RGB_STD).view(self.std.shape)\n\n    def forward(self, x):\n        x = (x-self.mean)/self.std\n        return x\n\ndef message(mode='print'):\n    asterisk = ' '\n    if mode==('print'):\n        loss = batch_loss\n    if mode==('log'):\n        loss = train_loss\n        if (iteration % iter_save == 0): asterisk = '*'\n\n    text = \\\n        ('%0.2e   %08d%s %6.2f | '%(rate, iteration, asterisk, epoch,)).replace('e-0','e-').replace('e+0','e+') + \\\n        '%4.3f  %4.3f   | '%(*valid_loss,) + \\\n        '%4.3f   | '%(loss) + \\\n        '%s' % ((time.time() - start_timer))\n\n    return text\n\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n# class Lookahead(Optimizer):\n#     def __init__(self, optimizer, alpha=0.5, k=6):\n\n#         if not 0.0 <= alpha <= 1.0:\n#             raise ValueError(f'Invalid slow update rate: {alpha}')\n#         if not 1 <= k:\n#             raise ValueError(f'Invalid lookahead steps: {k}')\n\n#         self.optimizer = optimizer\n#         self.param_groups = self.optimizer.param_groups\n#         self.alpha = alpha\n#         self.k = k\n#         for group in self.param_groups:\n#             group[\"step_counter\"] = 0\n\n#         self.slow_weights = [\n#                 [p.clone().detach() for p in group['params']]\n#             for group in self.param_groups]\n\n#         for w in it.chain(*self.slow_weights):\n#             w.requires_grad = False\n#         self.state = optimizer.state\n\n#     def step(self, closure=None):\n#         loss = None\n#         if closure is not None:\n#             loss = closure()\n#         loss = self.optimizer.step()\n\n#         for group,slow_weights in zip(self.param_groups,self.slow_weights):\n#             group['step_counter'] += 1\n#             if group['step_counter'] % self.k != 0:\n#                 continue\n#             for p,q in zip(group['params'],slow_weights):\n#                 if p.grad is None:\n#                     continue\n#                 q.data.add_(p.data - q.data, alpha=self.alpha )\n#                 p.data.copy_(q.data)\n#         return loss\n\n# class RAdam(Optimizer):\n\n#     def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n#         defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n#         self.buffer = [[None, None, None] for ind in range(10)]\n#         super(RAdam, self).__init__(params, defaults)\n\n#     def __setstate__(self, state):\n#         super(RAdam, self).__setstate__(state)\n\n#     def step(self, closure=None):\n\n#         loss = None\n#         if closure is not None:\n#             loss = closure()\n\n#         for group in self.param_groups:\n\n#             for p in group['params']:\n#                 if p.grad is None:\n#                     continue\n#                 grad = p.grad.data.float()\n#                 if grad.is_sparse:\n#                     raise RuntimeError('RAdam does not support sparse gradients')\n\n#                 p_data_fp32 = p.data.float()\n\n#                 state = self.state[p]\n\n#                 if len(state) == 0:\n#                     state['step'] = 0\n#                     state['exp_avg'] = torch.zeros_like(p_data_fp32)\n#                     state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n#                 else:\n#                     state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n#                     state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n#                 exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n#                 beta1, beta2 = group['betas']\n\n#                 exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value = 1 - beta2)\n#                 exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n\n#                 state['step'] += 1\n#                 buffered = self.buffer[int(state['step'] % 10)]\n#                 if state['step'] == buffered[0]:\n#                     N_sma, step_size = buffered[1], buffered[2]\n#                 else:\n#                     buffered[0] = state['step']\n#                     beta2_t = beta2 ** state['step']\n#                     N_sma_max = 2 / (1 - beta2) - 1\n#                     N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n#                     buffered[1] = N_sma\n\n#                     # more conservative since it's an approximated value\n#                     if N_sma >= 5:\n#                         step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n#                     else:\n#                         step_size = 1.0 / (1 - beta1 ** state['step'])\n#                     buffered[2] = step_size\n\n#                 if group['weight_decay'] != 0:\n#                     p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n\n#                 # more conservative since it's an approximated value\n#                 if N_sma >= 5:\n#                     denom = exp_avg_sq.sqrt().add_(group['eps'])\n#                     p_data_fp32.addcdiv_(exp_avg, denom, value=-step_size * group['lr'])\n#                 else:\n#                     p_data_fp32.add_(exp_avg, alpha=-step_size * group['lr'])\n\n#                 p.data.copy_(p_data_fp32)\n\n#         return loss\n\n# class PlainRAdam(Optimizer):\n\n#     def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n#         defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n\n#         super(PlainRAdam, self).__init__(params, defaults)\n\n#     def __setstate__(self, state):\n#         super(PlainRAdam, self).__setstate__(state)\n\n#     def step(self, closure=None):\n\n#         loss = None\n#         if closure is not None:\n#             loss = closure()\n\n#         for group in self.param_groups:\n\n#             for p in group['params']:\n#                 if p.grad is None:\n#                     continue\n#                 grad = p.grad.data.float()\n#                 if grad.is_sparse:\n#                     raise RuntimeError('RAdam does not support sparse gradients')\n\n#                 p_data_fp32 = p.data.float()\n\n#                 state = self.state[p]\n\n#                 if len(state) == 0:\n#                     state['step'] = 0\n#                     state['exp_avg'] = torch.zeros_like(p_data_fp32)\n#                     state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n#                 else:\n#                     state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n#                     state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n#                 exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n#                 beta1, beta2 = group['betas']\n\n#                 exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n#                 exp_avg.mul_(beta1).add_( grad, alpha= 1 - beta1)\n\n#                 state['step'] += 1\n#                 beta2_t = beta2 ** state['step']\n#                 N_sma_max = 2 / (1 - beta2) - 1\n#                 N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n\n#                 if group['weight_decay'] != 0:\n#                     p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n\n#                 # more conservative since it's an approximated value\n#                 if N_sma >= 5:\n#                     step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n#                     denom = exp_avg_sq.sqrt().add_(group['eps'])\n#                     p_data_fp32.addcdiv_(exp_avg, denom, value=-step_size)\n#                 else:\n#                     step_size = group['lr'] / (1 - beta1 ** state['step'])\n#                     p_data_fp32.add_(exp_avg, alpha=-step_size )\n\n#                 p.data.copy_(p_data_fp32)\n\n#         return loss\n\n\ndef get_learning_rate(optimizer):\n    return optimizer.param_groups[0]['lr']","metadata":{"papermill":{"duration":0.053647,"end_time":"2022-08-16T19:03:00.359131","exception":false,"start_time":"2022-08-16T19:03:00.305484","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.701035Z","iopub.execute_input":"2022-08-19T09:29:08.701568Z","iopub.status.idle":"2022-08-19T09:29:08.727044Z","shell.execute_reply.started":"2022-08-19T09:29:08.701520Z","shell.execute_reply":"2022-08-19T09:29:08.725815Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Augments","metadata":{"papermill":{"duration":0.005519,"end_time":"2022-08-16T19:03:00.370356","exception":false,"start_time":"2022-08-16T19:03:00.364837","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def valid_augment5(image, mask, organ):\n    #image, mask  = do_crop(image, mask, image_size, xy=(None,None))\n    return image, mask\n\ndef train_augment5b(image, mask, organ):\n    image, mask = do_random_flip(image, mask)\n    image, mask = do_random_rot90(image, mask)\n\n    for fn in np.random.choice([\n        lambda image, mask: (image, mask),\n        #lambda image, mask: do_random_noise(image, mask, mag=0.1),\n        #lambda image, mask: do_random_contast(image, mask, mag=0.40),\n        lambda image, mask: do_random_hsv(image, mask, mag=[0.40, 0.40, 0])\n    ], 2): image, mask = fn(image, mask)\n\n    for fn in np.random.choice([\n        lambda image, mask: (image, mask),\n        lambda image, mask: do_random_rotate_scale(image, mask, angle=45, scale=[0.50, 2.0]),\n    ], 1): image, mask = fn(image, mask)\n\n    return image, mask","metadata":{"papermill":{"duration":0.016754,"end_time":"2022-08-16T19:03:00.392910","exception":false,"start_time":"2022-08-16T19:03:00.376156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.730329Z","iopub.execute_input":"2022-08-19T09:29:08.730800Z","iopub.status.idle":"2022-08-19T09:29:08.741318Z","shell.execute_reply.started":"2022-08-19T09:29:08.730762Z","shell.execute_reply":"2022-08-19T09:29:08.740208Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def do_random_flip(image, mask):\n    if np.random.rand()>0.5:\n        image = cv2.flip(image,0)\n        mask = cv2.flip(mask,0)\n    if np.random.rand()>0.5:\n        image = cv2.flip(image,1)\n        mask = cv2.flip(mask,1)\n    if np.random.rand()>0.5:\n        image = image.transpose(1,0,2)\n        mask = mask.transpose(1,0)\n    \n    image = np.ascontiguousarray(image)\n    mask = np.ascontiguousarray(mask)\n    return image, mask\n\ndef do_random_rot90(image, mask):\n    r = np.random.choice([\n        0,\n        cv2.ROTATE_90_CLOCKWISE,\n        cv2.ROTATE_90_COUNTERCLOCKWISE,\n        cv2.ROTATE_180,\n    ])\n    if r==0:\n        return image, mask\n    else:\n        image = cv2.rotate(image, r)\n        mask = cv2.rotate(mask, r)\n        return image, mask\n    \ndef do_random_contast(image, mask, mag=0.3): #this thing kills the image and sets all pixels to 1\n    alpha = 1 + random.uniform(-1,1)*mag\n    image = image * alpha\n    image = np.clip(image,0,1)\n    return image, mask\n\ndef do_random_hsv(image, mask, mag=[0.15,0.25,0.25]):\n    image = (image*255).astype(np.uint8)\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    h = hsv[:, :, 0].astype(np.float32)  # hue\n    s = hsv[:, :, 1].astype(np.float32)  # saturation\n    v = hsv[:, :, 2].astype(np.float32)  # value\n    h = (h*(1 + random.uniform(-1,1)*mag[0]))%180\n    s =  s*(1 + random.uniform(-1,1)*mag[1])\n    v =  v*(1 + random.uniform(-1,1)*mag[2])\n\n    hsv[:, :, 0] = np.clip(h,0,180).astype(np.uint8)\n    hsv[:, :, 1] = np.clip(s,0,255).astype(np.uint8)\n    hsv[:, :, 2] = np.clip(v,0,255).astype(np.uint8)\n    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    image = image.astype(np.float32)/255\n    return image, mask\n\ndef do_random_noise(image, mask, mag=0.1): #also seems to kill the image and set to 1\n    height, width = image.shape[:2]\n    noise = np.random.uniform(-1,1, (height, width,1))*mag\n    image = image + noise\n    image = np.clip(image,0,1)\n    return image, mask\n\ndef do_random_rotate_scale(image, mask, angle=30, scale=[0.8,1.2] ):\n    angle = np.random.uniform(-angle, angle)\n    scale = np.random.uniform(*scale) if scale is not None else 1\n    \n    height, width = image.shape[:2]\n    center = (height // 2, width // 2)\n    \n    transform = cv2.getRotationMatrix2D(center, angle, scale)\n    image = cv2.warpAffine( image, transform, (width, height), flags=cv2.INTER_LINEAR,\n                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n    mask  = cv2.warpAffine( mask, transform, (width, height), flags=cv2.INTER_LINEAR,\n                            borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n    return image, mask","metadata":{"papermill":{"duration":0.024978,"end_time":"2022-08-16T19:03:00.423769","exception":false,"start_time":"2022-08-16T19:03:00.398791","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.743228Z","iopub.execute_input":"2022-08-19T09:29:08.743643Z","iopub.status.idle":"2022-08-19T09:29:08.764810Z","shell.execute_reply.started":"2022-08-19T09:29:08.743608Z","shell.execute_reply":"2022-08-19T09:29:08.763717Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# dummy_mask = np.zeros( (2023, 2023, 1) )\n# dummy_mask[ dummy_mask.shape[0] // 2 : dummy_mask.shape[0] // 2 + 100, \n#            dummy_mask.shape[0] // 2 : dummy_mask.shape[0] // 2 + 100] = 1\n# # dummy_mask[150 : 170, 220 : 240] = 1\n# # dummy_mask[300 : 320, 150 : 170] = 1\n# dummy_mask[1000 : 1100, 450 : 550] = 1\n# dummy_mask[1300 : 1400, 500 : 600] = 1\n# dummy_mask[1100 : 1200, 700 : 800] = 1\n# dummy_mask[800 : 900, 1000 : 1100] = 1\n# dummy_mask[1350 : 1450, 1250 : 1350] = 1\n\n# plt.imshow(dummy_mask)","metadata":{"papermill":{"duration":0.012714,"end_time":"2022-08-16T19:03:00.442141","exception":false,"start_time":"2022-08-16T19:03:00.429427","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.766234Z","iopub.execute_input":"2022-08-19T09:29:08.766815Z","iopub.status.idle":"2022-08-19T09:29:08.775777Z","shell.execute_reply.started":"2022-08-19T09:29:08.766777Z","shell.execute_reply":"2022-08-19T09:29:08.774821Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"papermill":{"duration":0.005493,"end_time":"2022-08-16T19:03:00.454279","exception":false,"start_time":"2022-08-16T19:03:00.448786","status":"completed"},"tags":[]}},{"cell_type":"code","source":"image_size = 512 # 256 #changed\n\nclass HubmapDataset(Dataset):\n    def __init__(self, df, augment=None):\n\n        self.df = df\n        self.augment = augment\n        self.length = len(self.df)\n        self.organ_to_label = {'kidney' : 0,\n                               'prostate' : 1,\n                               'largeintestine' : 2,\n                               'spleen' : 3,\n                               'lung' : 4}\n\n    def __str__(self):\n        string = ''\n        string += '\\tlen = %d\\n' % len(self)\n\n        d = self.df.organ.value_counts().to_dict()\n        for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n            string +=  '%24s %3d (%0.3f) \\n'%(k, d.get(k,0), d.get(k,0)/len(self.df))\n        return string\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, index):\n        d = self.df.iloc[index]\n        img_height = self.df.loc[index, 'img_height']\n        img_width = self.df.loc[index, 'img_width']\n        organ = self.organ_to_label[d.organ]\n\n        image = cv2.cvtColor(tifffile.imread(os.path.join(TRAIN, f'{d.id}.tiff')), cv2.COLOR_BGR2RGB)\n        \n        rle_mask = self.df.loc[index, 'rle']\n        mask = rle_decode(rle_mask, (img_height, img_width))\n        #mask = cv2.cvtColor(mask, cv2.IMREAD_GRAYSCALE)\n        #mask = cv2.imread(os.path.join(MASKS,fname),cv2.IMREAD_GRAYSCALE)\n        mask = np.expand_dims(mask, axis = 2)\n        #print(mask.shape)\n        \n        image = image.astype(np.float32)/255\n        #mask  = mask.astype(np.float32)/255\n        mask = mask.astype(np.float32)\n\n        s = d.pixel_size/0.4 * (image_size/3000)\n        image = cv2.resize(image,dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n        mask  = cv2.resize(mask, dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n\n        if self.augment is not None:\n            image, mask = self.augment(image, mask, organ)\n\n\n        r ={}\n        r['index']= index\n        r['organ'] = torch.tensor([organ], dtype=torch.long)\n        r['image'] = image_to_tensor(image)\n        r['mask' ] = mask_to_tensor(mask)\n        return r","metadata":{"papermill":{"duration":0.02051,"end_time":"2022-08-16T19:03:00.480870","exception":false,"start_time":"2022-08-16T19:03:00.460360","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.778470Z","iopub.execute_input":"2022-08-19T09:29:08.778900Z","iopub.status.idle":"2022-08-19T09:29:08.792034Z","shell.execute_reply.started":"2022-08-19T09:29:08.778844Z","shell.execute_reply":"2022-08-19T09:29:08.790999Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('../input/hubmap-organ-segmentation/train.csv')\n# ds = HubmapDataset(df)","metadata":{"papermill":{"duration":0.01215,"end_time":"2022-08-16T19:03:00.498755","exception":false,"start_time":"2022-08-16T19:03:00.486605","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.793631Z","iopub.execute_input":"2022-08-19T09:29:08.794873Z","iopub.status.idle":"2022-08-19T09:29:08.802016Z","shell.execute_reply.started":"2022-08-19T09:29:08.794764Z","shell.execute_reply":"2022-08-19T09:29:08.801105Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"papermill":{"duration":0.00545,"end_time":"2022-08-16T19:03:00.509765","exception":false,"start_time":"2022-08-16T19:03:00.504315","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class FPN(nn.Module):\n    def __init__(self, input_channels:list, output_channels:list):\n        super().__init__()\n        self.convs = nn.ModuleList(\n            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n            for in_ch, out_ch in zip(input_channels, output_channels)])\n        \n    def forward(self, xs:list, last_layer):\n        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear') \n               for i,(c,x) in enumerate(zip(self.convs, xs))]\n        hcs.append(last_layer)\n        return torch.cat(hcs, dim=1)\n\nclass UnetBlock(nn.Module):\n    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n                 self_attention:bool=False, **kwargs):\n        super().__init__()\n        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n        self.bn = nn.BatchNorm2d(x_in_c)\n        ni = up_in_c//2 + x_in_c\n        nf = nf if nf is not None else max(up_in_c//2,32)\n        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n        s = left_in\n        up_out = self.shuf(up_in)\n        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n        return self.conv2(self.conv1(cat_x))\n        \nclass _ASPPModule(nn.Module):\n    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n        super().__init__()\n        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n        self.bn = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU()\n\n        self._init_weight()\n\n    def forward(self, x):\n        x = self.atrous_conv(x)\n        x = self.bn(x)\n\n        return self.relu(x)\n\n    def _init_weight(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                torch.nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\nclass ASPP(nn.Module):\n    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None): #changed\n        super().__init__()\n        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n        self.aspps = nn.ModuleList(self.aspps)\n        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n                        nn.BatchNorm2d(mid_c), nn.ReLU())\n        out_c = out_c if out_c is not None else mid_c\n        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n        self._init_weight()\n\n    def forward(self, x):\n        x0 = self.global_pool(x)\n        xs = [aspp(x) for aspp in self.aspps]\n        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n        x = torch.cat([x0] + xs, dim=1)\n        return self.out_conv(x)\n    \n    def _init_weight(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                torch.nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n\nclass config:\n    pretrained_root = '../input/efficientnet-pytorch/'\n    efficient_net_encoders = {\n        \"efficientnet-b0\": {\n            \"out_channels\": (3, 32, 24, 40, 112, 320),\n            \"stage_idxs\": (3, 5, 9, 16),\n            \"weight_path\": pretrained_root + \"efficientnet-b0-08094119.pth\"\n        },\n        \"efficientnet-b1\": {\n            \"out_channels\": (3, 32, 24, 40, 112, 320),\n            \"stage_idxs\": (5, 8, 16, 23),\n            \"weight_path\": pretrained_root + \"efficientnet-b1-dbc7070a.pth\"\n        },\n        \"efficientnet-b2\": {\n            \"out_channels\": (3, 32, 24, 48, 120, 352),\n            \"stage_idxs\": (5, 8, 16, 23),\n            \"weight_path\": pretrained_root + \"efficientnet-b2-27687264.pth\"\n        },\n        \"efficientnet-b3\": {\n            \"out_channels\": (3, 40, 32, 48, 136, 384),\n            \"stage_idxs\": (5, 8, 18, 26),\n            \"weight_path\": pretrained_root + \"efficientnet-b3-c8376fa2.pth\"\n        },\n        \"efficientnet-b4\": {\n            \"out_channels\": (3, 48, 32, 56, 160, 448),\n            \"stage_idxs\": (6, 10, 22, 32),\n            \"weight_path\": pretrained_root + \"efficientnet-b4-e116e8b3.pth\"\n        },\n        \"efficientnet-b5\": {\n            \"out_channels\": (3, 48, 40, 64, 176, 512), #changed\n            \"stage_idxs\": (8, 13, 27, 39),\n            \"weight_path\": pretrained_root + \"efficientnet-b5-586e6cc6.pth\"\n        },\n        \"efficientnet-b6\": {\n            \"out_channels\": (3, 56, 40, 72, 200, 576),\n            \"stage_idxs\": (9, 15, 31, 45),\n            \"weight_path\": pretrained_root + \"efficientnet-b6-c76e70fd.pth\"\n        },\n        \"efficientnet-b7\": {\n            \"out_channels\": (3, 64, 48, 80, 224, 640),\n            \"stage_idxs\": (11, 18, 38, 55),\n            \"weight_path\": pretrained_root + \"efficientnet-b7-dcc49843.pth\"\n        }\n    }\n    model = 'efficientnet-b7'\n    \nclass EfficientNetEncoder(EfficientNet):\n    def __init__(self, stage_idxs, out_channels, model_name, depth=5):\n\n        blocks_args, global_params = get_model_params(model_name, override_params=None)\n        super().__init__(blocks_args, global_params)\n        \n        cfg = config.efficient_net_encoders[model_name]\n\n        self._stage_idxs = stage_idxs\n        self._out_channels = out_channels\n        self._depth = depth\n        self._in_channels = 3\n\n        del self._fc\n        self.load_state_dict(torch.load(cfg['weight_path']))\n\n    def get_stages(self):\n        return [\n            nn.Identity(),\n            nn.Sequential(self._conv_stem, self._bn0, self._swish),\n            self._blocks[:self._stage_idxs[0]],\n            self._blocks[self._stage_idxs[0]:self._stage_idxs[1]],\n            self._blocks[self._stage_idxs[1]:self._stage_idxs[2]],\n            self._blocks[self._stage_idxs[2]:],\n        ]\n\n    def forward(self, x):\n        stages = self.get_stages()\n\n        block_number = 0.\n        drop_connect_rate = self._global_params.drop_connect_rate\n\n        features = []\n        for i in range(self._depth + 1):\n\n            # Identity and Sequential stages\n            if i < 2:\n                x = stages[i](x)\n\n            # Block stages need drop_connect rate\n            else:\n                for module in stages[i]:\n                    drop_connect = drop_connect_rate * block_number / len(self._blocks)\n                    block_number += 1.\n                    x = module(x, drop_connect)\n\n            features.append(x)\n\n        return features\n\n    def load_state_dict(self, state_dict, **kwargs):\n        state_dict.pop(\"_fc.bias\")\n        state_dict.pop(\"_fc.weight\")\n        super().load_state_dict(state_dict, **kwargs)  \n        \n\nclass EffUnet(nn.Module):\n    def __init__(self, model_name, stride=1):\n        super().__init__()\n        \n        cfg = config.efficient_net_encoders[model_name]\n        stage_idxs = cfg['stage_idxs']\n        out_channels = cfg['out_channels']\n        \n        self.encoder = EfficientNetEncoder(stage_idxs, out_channels, model_name)\n\n        #aspp with customized dilatations\n        self.aspp = ASPP(out_channels[-1], 256, out_c=384, \n                         dilations=[stride*1, stride*2, stride*3, stride*4])\n        self.drop_aspp = nn.Dropout2d(0.5)\n        #decoder\n        self.dec4 = UnetBlock(384, out_channels[-2], 256)\n        self.dec3 = UnetBlock(256, out_channels[-3], 128)\n        self.dec2 = UnetBlock(128, out_channels[-4], 64)\n        self.dec1 = UnetBlock(64, out_channels[-5], 32)\n        self.fpn = FPN([384, 256, 128, 64], [16]*4)\n        self.drop = nn.Dropout2d(0.1)\n        self.final_conv = ConvLayer(32+16*4, 1, ks=1, norm_type=None, act_cls=None)\n        \n        self.rgb = RGB()\n        \n    def forward(self, batch):\n        x = batch['image']\n        B, C, H, W = x.shape\n        x = self.rgb(x)\n        enc0, enc1, enc2, enc3, enc4 = self.encoder(x)[-5:]\n        enc5 = self.aspp(enc4)\n        dec3 = self.dec4(self.drop_aspp(enc5), enc3)\n        dec2 = self.dec3(dec3,enc2)\n        dec1 = self.dec2(dec2,enc1)\n        dec0 = self.dec1(dec1,enc0)\n        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n        x = self.final_conv(self.drop(x))\n        x = F.interpolate(x, size = 512, mode = 'bilinear') #changed\n        return x","metadata":{"papermill":{"duration":0.049669,"end_time":"2022-08-16T19:03:00.565172","exception":false,"start_time":"2022-08-16T19:03:00.515503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.803707Z","iopub.execute_input":"2022-08-19T09:29:08.804340Z","iopub.status.idle":"2022-08-19T09:29:08.847471Z","shell.execute_reply.started":"2022-08-19T09:29:08.804306Z","shell.execute_reply":"2022-08-19T09:29:08.846378Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# net = EffUnet(config.model)\n# del net","metadata":{"papermill":{"duration":0.013343,"end_time":"2022-08-16T19:03:00.584292","exception":false,"start_time":"2022-08-16T19:03:00.570949","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.852216Z","iopub.execute_input":"2022-08-19T09:29:08.853474Z","iopub.status.idle":"2022-08-19T09:29:08.858632Z","shell.execute_reply.started":"2022-08-19T09:29:08.853342Z","shell.execute_reply":"2022-08-19T09:29:08.857647Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def run_check_net():\n    batch_size = 2\n    image_size = 512 #256 #changed\n\n    #---\n    batch = {\n        'image' : torch.from_numpy( np.random.uniform(-1,1,(batch_size,3,image_size,image_size)) ).float(),\n        'mask'  : torch.from_numpy( np.random.choice(2,(batch_size,1,image_size,image_size)) ).float(),\n        'organ' : torch.from_numpy( np.random.choice(5,(batch_size)) ).long(),\n    }\n    \n    batch = {k:v.cuda() for k,v in batch.items()}\n\n    net = EffUnet(config.model).cuda()\n\n    with torch.no_grad():\n        with torch.cuda.amp.autocast(enabled=True):\n            output = net(batch)\n\n    print('batch')\n    for k,v in batch.items():\n        print('%32s :'%k, v.shape)\n\n    print('output')\n    print( (' '*35 + f'{output.shape}'))\n\n#run_check_net()","metadata":{"papermill":{"duration":0.016373,"end_time":"2022-08-16T19:03:00.606286","exception":false,"start_time":"2022-08-16T19:03:00.589913","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.860193Z","iopub.execute_input":"2022-08-19T09:29:08.861229Z","iopub.status.idle":"2022-08-19T09:29:08.870569Z","shell.execute_reply.started":"2022-08-19T09:29:08.861193Z","shell.execute_reply":"2022-08-19T09:29:08.869373Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Folds","metadata":{"papermill":{"duration":0.00547,"end_time":"2022-08-16T19:03:00.617292","exception":false,"start_time":"2022-08-16T19:03:00.611822","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def make_fold(fold = 3):\n    df = pd.read_csv(LABELS)\n\n    num_fold = 4\n    skf = KFold(n_splits = num_fold, shuffle = True,random_state = 42)\n\n    df.loc[:,'fold']=-1\n    for f,(t_idx, v_idx) in enumerate(skf.split(X=df['id'], y=df['organ'])):\n        df.iloc[v_idx,-1]=f\n\n    #check\n    if 0:\n        for f in range(num_fold):\n            train_df=df[df.fold!=f].reset_index(drop=True)\n            valid_df=df[df.fold==f].reset_index(drop=True)\n\n            print('fold %d'%f)\n            t = train_df.organ.value_counts().to_dict()\n            v = valid_df.organ.value_counts().to_dict()\n            for k in ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']:\n                print('%32s %3d (%0.3f)  %3d (%0.3f)'%(k,t.get(k,0),t.get(k,0)/len(train_df),v.get(k,0),v.get(k,0)/len(valid_df)))\n\n            print('')\n            zz=0\n\n    train_df=df[df.fold!=fold].reset_index(drop=True)\n    valid_df=df[df.fold==fold].reset_index(drop=True)\n    return train_df,valid_df","metadata":{"papermill":{"duration":0.017484,"end_time":"2022-08-16T19:03:00.640381","exception":false,"start_time":"2022-08-16T19:03:00.622897","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.872189Z","iopub.execute_input":"2022-08-19T09:29:08.872811Z","iopub.status.idle":"2022-08-19T09:29:08.884125Z","shell.execute_reply.started":"2022-08-19T09:29:08.872776Z","shell.execute_reply":"2022-08-19T09:29:08.882996Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Competition metric","metadata":{"papermill":{"duration":0.005895,"end_time":"2022-08-16T19:03:00.651958","exception":false,"start_time":"2022-08-16T19:03:00.646063","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def compute_dice_score(probability, mask, smooth = 1):\n    N = len(probability)\n    p = probability.reshape(N,-1)\n    t = mask.reshape(N,-1)\n\n    p = p>0.5\n    t = t>0.5\n    uion = p.sum(-1) + t.sum(-1)\n    overlap = (p*t).sum(-1)\n    dice = 2*overlap/(uion+0.0001)\n    return dice","metadata":{"papermill":{"duration":0.013577,"end_time":"2022-08-16T19:03:00.671364","exception":false,"start_time":"2022-08-16T19:03:00.657787","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.885952Z","iopub.execute_input":"2022-08-19T09:29:08.887186Z","iopub.status.idle":"2022-08-19T09:29:08.894497Z","shell.execute_reply.started":"2022-08-19T09:29:08.887158Z","shell.execute_reply":"2022-08-19T09:29:08.893433Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{"papermill":{"duration":0.005378,"end_time":"2022-08-16T19:03:00.682366","exception":false,"start_time":"2022-08-16T19:03:00.676988","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def validate(net, valid_loader, debug = False):\n    \n    valid_num = 0\n    valid_probability = []\n    valid_mask = []\n    valid_loss = 0\n    \n    criterion = nn.BCEWithLogitsLoss()\n    \n    net = net.eval()\n    start_timer = time.time()\n    \n    for t, batch in enumerate(valid_loader):\n        \n        with torch.no_grad():\n            with amp.autocast(enabled = is_amp):\n                \n                batch_size = len(batch['index'])\n                batch['image'] = batch['image'].cuda()\n                batch['mask' ] = batch['mask' ].cuda()\n                batch['organ'] = batch['organ'].cuda()\n\n                output = net(batch)\n                \n                batch['mask'] = batch['mask'].unsqueeze(1)\n                loss = criterion(output, batch['mask'])\n        \n        valid_probability.append(output.data.cpu().numpy())\n        valid_mask.append(batch['mask'].data.cpu().numpy())\n        valid_num += batch_size\n        valid_loss += batch_size * loss.item()\n        \n        print('\\r %8d / %d  %s'%(valid_num, len(valid_loader.dataset),(time.time() - start_timer)),end='',flush=True)\n    \n    assert(valid_num == len(valid_loader.dataset))\n\n    probability = np.concatenate(valid_probability)\n    mask = np.concatenate(valid_mask)\n\n    loss = valid_loss/valid_num\n\n    dice = compute_dice_score(probability, mask)\n    dice = dice.mean()\n    \n    return [dice, loss]","metadata":{"papermill":{"duration":0.01812,"end_time":"2022-08-16T19:03:00.706195","exception":false,"start_time":"2022-08-16T19:03:00.688075","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.896217Z","iopub.execute_input":"2022-08-19T09:29:08.896795Z","iopub.status.idle":"2022-08-19T09:29:08.908921Z","shell.execute_reply.started":"2022-08-19T09:29:08.896761Z","shell.execute_reply":"2022-08-19T09:29:08.908019Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Initialize","metadata":{"papermill":{"duration":0.00551,"end_time":"2022-08-16T19:03:00.717363","exception":false,"start_time":"2022-08-16T19:03:00.711853","status":"completed"},"tags":[]}},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\n\nfold = 3\n\nout_dir = root_dir + '/result/effnetb7/fold-%d' % (fold)\ninitial_checkpoint = None\n\nstart_lr = 5e-5\nbatch_size = 8\n\n## setup  ----------------------------------------\nfor f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n\n\nlog = open(out_dir+'/log.train.txt',mode='a')\nlog.write('\\n--- [START %s] %s\\n\\n' % ('EfficientNet-b7', '-' * 64))\nlog.write('\\n')\n\n## dataset ----------------------------------------\nlog.write('** dataset setting **\\n')\n\ntrain_df, valid_df = make_fold(fold)\n\ntrain_dataset = HubmapDataset(train_df, train_augment5b)\nvalid_dataset = HubmapDataset(valid_df, valid_augment5)\n\ntrain_loader  = DataLoader(\n    train_dataset,\n    sampler = RandomSampler(train_dataset),\n    batch_size  = batch_size,\n    drop_last   = True,\n    num_workers = 8,\n    pin_memory  = False,\n    worker_init_fn = lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id)\n)\n\nvalid_loader = DataLoader(\n    valid_dataset,\n    sampler = SequentialSampler(valid_dataset),\n    batch_size  = 8,\n    drop_last   = False,\n    num_workers = 4,\n    pin_memory  = False\n)\n\n\nlog.write('fold = %s\\n'%str(fold))\nlog.write('train_dataset : \\n%s\\n'%(train_dataset))\nlog.write('valid_dataset : \\n%s\\n'%(valid_dataset))\nlog.write('\\n')\n\n\n## net ----------------------------------------\nlog.write('** net setting **\\n')\n\nscaler = amp.GradScaler(enabled = is_amp)\nnet = EffUnet(config.model).cuda()\n\nif initial_checkpoint is not None:\n    f = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)\n    start_iteration = f['iteration']\n    start_epoch = f['epoch']\n    state_dict  = f['state_dict']\n    net.load_state_dict(state_dict,strict=False)  #True\nelse:\n    start_iteration = 0\n    start_epoch = 0\n\n\nlog.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\nlog.write('\\n')\n\n\n## optimiser ----------------------------------\nif 0: ##freeze\n    for p in net.stem.parameters():   p.requires_grad = False\n    pass\n\ndef freeze_bn(net):\n    for m in net.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.eval()\n            m.weight.requires_grad = False\n            m.bias.requires_grad = False\n            \n#freeze_bn(net)\n\n#-----------------------------------------------\n\noptimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr)\n#optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=start_lr), alpha=0.5, k=5)\n\nlog.write('optimizer\\n  %s\\n'%(optimizer))\nlog.write('\\n')\n\n#num_iteration = 1000*len(train_loader)\nnum_iteration = 9000\niter_log   = len(train_loader)*3 #479\niter_valid = iter_log\niter_save  = iter_log","metadata":{"papermill":{"duration":8.210001,"end_time":"2022-08-16T19:03:08.932978","exception":false,"start_time":"2022-08-16T19:03:00.722977","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:08.912638Z","iopub.execute_input":"2022-08-19T09:29:08.912901Z","iopub.status.idle":"2022-08-19T09:29:15.771199Z","shell.execute_reply.started":"2022-08-19T09:29:08.912877Z","shell.execute_reply":"2022-08-19T09:29:15.770197Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"papermill":{"duration":0.006146,"end_time":"2022-08-16T19:03:08.945358","exception":false,"start_time":"2022-08-16T19:03:08.939212","status":"completed"},"tags":[]}},{"cell_type":"code","source":"log.write('** start training here! **\\n')\nlog.write('   batch_size = %d \\n'%(batch_size))\nlog.write('                     |-------------- VALID ---------|---- TRAIN/BATCH ----------------\\n')\nlog.write('rate     iter  epoch | dice   loss   tp     tn     | loss           | time           \\n')\nlog.write('-------------------------------------------------------------------------------------\\n')\n\nvalid_loss = np.zeros(2,np.float32)\ntrain_loss = 0\nbatch_loss = 0\nsum_train_loss = 0\nsum_train = 0\n\nstart_timer = time.time()\niteration = start_iteration\nepoch = start_epoch\nrate = 0\naccum_iter = 4  \n\nwhile iteration < num_iteration:\n    for t, batch in enumerate(train_loader):\n\n        if iteration%iter_save==0:\n            if iteration != start_iteration:\n                torch.save({\n                    'state_dict': net.state_dict(),\n                    'iteration': iteration,\n                    'epoch': epoch,\n                }, out_dir + '/checkpoint/%08d.model.pth' %  (iteration))\n                pass\n\n\n        if (iteration%iter_valid==0):\n            valid_loss = validate(net, valid_loader)\n            pass\n\n\n        if (iteration%iter_log==0) or (iteration%iter_valid==0):\n            print('\\r', end='', flush=True)\n            log.write(message(mode='log') + '\\n')\n\n\n        # learning rate schduler ------------\n        rate = get_learning_rate(optimizer)\n\n        # one iteration update  -------------\n        batch_size = len(batch['index'])\n        \n        #print(batch_size, iteration, epoch)\n        batch['image'] = batch['image'].half().cuda()\n        batch['mask' ] = batch['mask' ].half().cuda()\n        batch['organ'] = batch['organ'].cuda()\n\n        \n        net.train()\n        net.output_type = ['loss']\n        if 1:\n            with amp.autocast(enabled = is_amp):\n                output = net(batch)\n                batch['mask'] = batch['mask'].unsqueeze(1)\n                loss = criterion(output, batch['mask'])\n                loss = loss / accum_iter \n                \n            \n            scaler.scale(loss).backward()\n\n            \n            \n            if ((t + 1) % accum_iter == 0) or (t + 1 == len(train_loader)):\n                scaler.unscale_(optimizer)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                \n                \n        # print statistics  --------\n        batch_loss = loss.item()\n        sum_train_loss += batch_loss\n        sum_train += 1\n        if t % 100 == 0:\n            train_loss = sum_train_loss / (sum_train + 1e-12)\n            sum_train_loss = 0\n            sum_train = 0\n\n        print('\\r', end='', flush=True)\n        print(message(mode='print'), end='', flush=True)\n        \n        epoch += 1 / len(train_loader)\n        iteration += 1\n    print()\n    torch.cuda.empty_cache()\n    \nlog.write('\\n')\nlog.close()","metadata":{"papermill":{"duration":2131.600859,"end_time":"2022-08-16T19:38:40.552279","exception":false,"start_time":"2022-08-16T19:03:08.951420","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:29:15.772821Z","iopub.execute_input":"2022-08-19T09:29:15.773370Z","iopub.status.idle":"2022-08-19T09:34:20.740297Z","shell.execute_reply.started":"2022-08-19T09:29:15.773326Z","shell.execute_reply":"2022-08-19T09:34:20.736931Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# sdifjpsidjfip gpsjdog sdopjgosd pdsgjo[sdg]","metadata":{"papermill":{"duration":0.110188,"end_time":"2022-08-16T19:38:40.786715","exception":false,"start_time":"2022-08-16T19:38:40.676527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-08-19T09:34:20.743927Z","iopub.status.idle":"2022-08-19T09:34:20.746552Z","shell.execute_reply.started":"2022-08-19T09:34:20.746281Z","shell.execute_reply":"2022-08-19T09:34:20.746307Z"},"trusted":true},"execution_count":null,"outputs":[]}]}